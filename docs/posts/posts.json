[
  {
    "path": "posts/2020-08-20-packages-r-conference-nyc/",
    "title": "Packages I Learned about at R Conference NYC",
    "description": "Packages I learned about attending R Conference NYC.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-08-20",
    "categories": [
      "data science",
      "programming",
      "R",
      "R conference"
    ],
    "contents": "\nThe R Conference took place this past weekend August 14-15. The event, usually held in New York City was held virtually and it went rather smoothly. Jared, Amada and the rest of the Lander Analytics team did a great job putting together a great virtual experience.\nAs an R newbie, I was blown away by the talks I watched. I continue to be amazed by the possibilities of R and how people from different fields are using the R language in their work.\nOne of my favorite things about R are the packages and there were no shortage of packages at this conference. I tried to keep a list of packages that were mentioned but I probably failed as there were so many. I would love to try every package mentioned at this conference but for right now, I want to discuss a few that really interested me.\ncrosstalk\nI first heard of the crosswalk package through Tom Mock’s talk on RMarkdown. I was very excited for this talk as I use RMarkdown pretty heavily and could use some cool tips and tricks. Crosstalk is a R package that adds on to the HTMLwidgets package. It provides the building blocks for HTMLwidgets to communicate with one another with or without Shiny. Basically this package allows for cross-widget interactivity.\nRead more on the {crosstalk} package here.\ntmap\nThis package was introduced to me during Emily Dodwell’s talk about visualizing spatiotemporal data. This package allows you to create thematic maps. The maps I saw in Emily’s talk were really cool and I’d like to one day create maps like those. At the end of her talk she recommended a book called Geocomputation in R that I’ll have to look into.\nRead more on the {tmap} package here and here.\nwidyr\nWe talk a lot about the importance of tidy data in the R community, particularly when dealing with the tidyverse. However, sometimes we may need to un-tidy the data to perform certain mathematical operations. This is where widyr comes in. Widyr is a package developed by David Robinson, Julia Siege and Kanishka Misra that un-tidys the dataset into a wide matrix, performs some processing, then re-tidys the dataset. As I learn more about math and stats in R, I hope to take advantage of this package.\nRead more on the {widyr} package here.\narrow\nIf you were to ask me how to load data in R about two months ago I would have told you about the readr package. I would have also shared that you can see the first and last parts of a dataset using the head() and tail() functions. Since that time however, I’ve been introduced to other ways to load data such as data.table, vroom and now arrow. The arrow package, created by Ursa Labs allows for the fast loading and processing of large data. In their talk, Wes McKinney and Dr. Neal Richardson showed us how much faster arrow was in comparison to read.csv or read_csv which I normally use to load data. As my datasets become larger though, I’ll start taking a look at arrow.\nRead more about the {arrow} package here.\nfunneljoin\nEmily Robinson introduced the funneljoin package during her talk. Funneljoin allows you to do time-based joins to analyze a sequence of events. With this package you can analyze behavior funnels. Emily stated in her blog post, “If you work with data where you have events with their time and associated user, you probably have a problem funneljoin can help with.” One example Emily provided was an e-commerce site where you want to find out all the times an item was clicked on then added to the cart within 2 days. I’ve worked with online shoppers data in a past blog post and would like to try out this package using similar data sets.\nRead more about {funneljoin} here. You can also check out Emily’s blog post here.\nbootstraplib\nOnce upon a time I took a front-end web development course. In addition to HTML, CSS and the little bit of Javascript and jQuery I learned, I also learned about Bootstrap and Sass. I even used a bootstrap theme for my website at one point! So when Dr. Jacqueline Nolis talked about using bootstraplib for her shiny website, I was all ears. Boostraplib is a package that provides tools for styling Shiny apps and RMarkdown documents using Bootstrap Sass. I do want to get into Shiny and I use already use RMarkdown so I’ll definitely want to experiment with this package.\nRead more about {bootstraplib} package here.\nfable\nThe last R package I want to mention on this list is fable. Fable provides a collection of time series forecasting models. According to the fable’s READ.me on Github, these models work within the fable framework, which provides the tools to evaluate, visualize, and combine models in a workflow consistent with the tidyverse. Dr. Rob J. Hyndman, who is one of the authors of the fable package, did an awesome talk discussing ensemble forecasts where he used this package. I am still very new when it comes to time series and forecasting models. I mean, I know what they are but have yet to build any sort of model. I hope to change that soon especially now that I know about this package.\nRead more on the {fable} package here.\nI learned so much during my attendance of the R conference. There are so many things I want to try. I left this conference feeling inspired to keep going and keep learning R. One day I hope to do a talk and build something that inspires someone like the talks at this conference inspired me. Until next time…\n\n\n\n",
    "preview": {},
    "last_modified": "2020-10-13T20:28:42-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-07-16-relational-data-string-manipulation/",
    "title": "String Manipulation and Relational Data",
    "description": "Learning more string manipulation and relational data in R.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-07-16",
    "categories": [
      "data science",
      "programming",
      "R",
      "joins",
      "string manipulation",
      "relational data"
    ],
    "contents": "\n\n    pre code {\n      white-space: pre-wrap;\n    }\nHello everyone! Long time no see. I’m happy to be back with another post with this post focusing on what I learned in Dataquest’s String Manipulation and Relational Data lesson. I thought I switch up these posts a bit. Instead of sharing every single thing I’ve learned in these lessons, I have decided to focus on functions and concepts that stick out to me.\nIn this lesson I learned about manipulating strings to create new variables and relational data using joins and keys. This post will focus on two new concepts I learned: the parse_number() function and the types of joins that are used to combine data frames.\nParse_number()\nThe parse_number() function is part of the readr package and it drops any non-numeric characters before or after the first number. The example below shows that every non-numeric character was dropped to parse out the number 87.35.\n\n\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(jpeg)\n\n\n\n\n\nparse_number(\"This shirt cost $87.35, that is so expensive!\")\n\n\n[1] 87.35\n\nWhat happens when I have more than one numeric character I want to extract? This is where regex, better known as regular expressions come in. However, I’ll probably cover more regular expression topics in a future post.\nJoins\nThe biggest takeaway from this lesson had to with joins. Recall from a previous post that to combine vectors and matrices, I used rbind() to combine by rows and cbind() to combine by columns. When you combine vectors and matrices, the values of the rows and columns are combined based on their position.\nIf I wanted to join data frames, however, I would join the columns together based on matching values of a variable. A key is a variable that is used to combine data frames. We use the dplyr package to work with data frames. The dplyr functions used to combine tables are for executing mutating joins. Mutating joins add new variables to a data frame based on matching values in another data frame. The concept of having multiple tables containing data that you are interested in relationships between is referred to as relational data.\nWhen I learned of joins in R, I was excited because it immediately reminded me of learning of joins in Tableau. I’ve also heard of joins in SQL so I thought this topic would be very important for me to learn, understand and eventually share. Enough of me yapping, let’s get to the joins!\nInner Join\nInner joins match pairs of variables in two data frames when their values of the key are the same. Any rows with unmatched keys are dropped. Let’s look at the example below.\nA few weeks back, I decided to look up some information about the top five paperback nonfiction books on the New York Times’ bestseller list. From my research, I created the two data frames below. The first data frame is referred to as paperback_nonfiction. The second data frame is referred to as publisher_info.\n\n\npaperback_nonfiction <- data.frame(\"ISBN_13\" = c(9780807047416, 9781580058827, 9780465060869, 9781631494536, 9781568585987),\n                                   \"Title\" = c(\"White Fragility\", \"So You Want to Talk about Race\", \"Why Are All The Blacks Sitting Together in the Cafeteria\", \"The Color of Law\", \"Stamped From The Beginning\"),\n                                   \"Author\" = c(\"Robin DiAngelo\", \"Ijeoma Oluo\", \"Beverly Tatum\", \"Richard Rothstein\", \"Ibram X. Kendi\"),\n                                   \"Weeks_on_List\" = c(94, 5, 3, 8, 5))\n\n\n\n\n\npublisher_info <- data.frame(\"Publisher\" = c(\"Beacon Press\", \"Seal Press\", \"Basic Books\", \"Liveright\", \"Bold Type Books\"),\n                             \"ISBN_13\" = c(9780807047415, 9781580058827, 9780465060869, 9781631494536, 9781568585987),\n                             \"Pages\" = c(192, 272, 464, 368, 608),\n                             \"Amazon_Prices\" = c(10.62, 10.19, 11.39, 9.99, 11.99))\n\n\n\nAfter creating the data frames, I decided to perform an inner join because I wanted to only include results that appeared in both data frames I’m joining. Using the code below, I joined the two data frames using the variable ISBN_13 as my key.\nAs you can see, when I performed an inner join, it kept the rows that matched from the data frames. Notice that the first row of the paperback_nonfiction data frame and the first row of the publisher_info data frame were dropped because those two rows were not a match. The data frame below is referred to as best_paperback_nonfiction.\n\n\nbest_paperback_nonfiction <- paperback_nonfiction %>%\n  inner_join(publisher_info, by = \"ISBN_13\")\n\n\n\n\n\n\nOuter Joins\nOuter joins keep values that appear in at least one of the data frames you’re combining. Any missing values will be filled in with “NA”. There are three types of outer joins:\nleft join\nright join\nfull join\nLet’s go over these in more detail.\nLeft Join\nA left join keeps all the values in the data frame to the left and drops the values from the data frame to the right that have no key match.\nI used the code below to perform a left join on the paperback_nonfiction and publisher_info data frames I used before.\nThe result of the following code is that when the data frames are joined together, the values of the data frame on the right (the publisher_info data frame) are dropped.\n\n\nbest_paperback_nonfiction <- paperback_nonfiction %>%\n  left_join(publisher_info, by = \"ISBN_13\")\n\n\n\n\n\n\nRight Join\nA right join keeps values in the data frame to the right and drops the values from the data frame to the left that have no key match.\nThe result of the following code is that when the data frames are joined together, the values of the data frame on the left (the paperback_nonfiction data frame) are dropped.\n\n\nbest_paperback_nonfiction <- paperback_nonfiction %>%\n  right_join(publisher_info, by = \"ISBN_13\")\n\n\n\n\n\n\nFull Join\nA full join keeps all observations from the data frames you’re joining. Again when there is no key match, values are dropped.\nThe result of the following code is that when the data frames are joined together, the values of the data frame on the left (the paperback_nonfiction data frame) and the data frame on the right (the publisher_info data frame) are dropped since they are not a match.\n\n\nbest_paperback_nonfiction <- paperback_nonfiction %>%\n  full_join(publisher_info, by = \"ISBN_13\")\n\n\n\n\n\n\nWhew! Okay I know that was a lot but just wanted to share. The more I do these posts the better I understand these important R and programming concepts. Until next time…\n\n\n\n",
    "preview": "posts/2020-07-16-relational-data-string-manipulation/inner_join.jpg",
    "last_modified": "2020-10-16T23:13:23-04:00",
    "input_file": "string-relational-data.utf8.md"
  },
  {
    "path": "posts/2020-05-29-data-cleaning-with-r/",
    "title": "Data Cleaning With R",
    "description": "My experience learning to do some data cleaning in R.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-05-29",
    "categories": [
      "data science",
      "programming",
      "R",
      "data cleaning"
    ],
    "contents": "\n\n    pre code {\n      white-space: pre-wrap;\n    }\nI have now reached the Data Cleaning in R section of DataQuest’s Data Analyst in R track. I had some difficulty finding a messy data set to clean. I decided to practice cleaning two datasets.\nI’ll first discuss the first data set which comes from UCI Machine Learning Repository. In the repository, I found the Purchasing Intention Data Set. This data set explores the intentions of online shoppers using metrics like Bounce Rate and Traffic Type.\nThe first thing I wanted to do was to convert the columns Weekend and Revenue from logical(TRUE/FALSE) columns to numeric columns. There are a few ways to do this as shown in the screenshot below.\n\n\n# Converting a single column to numeric:\nonline_shoppers_number <- online_shoppers_intention %>%\n  mutate(`Weekend` = as.numeric(`Weekend`))\n\n\n\n\n\n# Converting multiple columns to numeric with column names:\nonline_shoppers_number <- online_shoppers_intention %>%\n  mutate_at(vars(Weekend, Revenue), as.numeric)\n\n\n\n\n\n# Converting multiple columns to numeric with column indexes:\nonline_shoppers_number <- online_shoppers_intention %>%\n  mutate_at((17:18), as.numeric)\n\n\n\nI decided to use the second script to convert the Weekend and Revenue columns to numeric columns. The first photo shown is before I converted the columns to numeric and the second photo shows the columns after I converted them to numeric columns.\n\n\n\n\n\n\nThe next thing I decided to do was to filter the data frame so that values for the ProductRelated column are more than 15. The ProductRelated column refers to products pages of a shopping site. I filtered the data using the script shown below.\n\n\nonline_shoppers_number <-online_shoppers_number %>%\n  filter(ProductRelated > 15)\n\n\n\nThis is what the column looked like after I filtered it:\n\n\n\nI then decided to group the data by Month and Visitor Type and sum up the columns using Informational and Informational Duration columns.\nThe results are shown below.\n\n\nonline_shoppers_group <- online_shoppers_number %>%\n  group_by(`Month`, `VisitorType`)\n\n\n\n\n\nonline_shoppers_informational <- online_shoppers_group %>%\n  mutate(`Informational_Total` = `Informational` + `Informational_Duration`)\n\nonline_shoppers_informational\n\n\n# A tibble: 6,726 x 19\n# Groups:   Month, VisitorType [22]\n   Administrative Administrative_… Informational Informational_D…\n            <dbl>            <dbl>         <dbl>            <dbl>\n 1              0              0               0                0\n 2              0              0               0                0\n 3              2             53               0                0\n 4              0              0               0                0\n 5              4             64.6             0                0\n 6              1              6               1                0\n 7              0              0               0                0\n 8              1              9               0                0\n 9              0              0               0                0\n10              4             56               2              120\n# … with 6,716 more rows, and 15 more variables:\n#   ProductRelated <dbl>, ProductRelated_Duration <dbl>,\n#   BounceRates <dbl>, ExitRates <dbl>, PageValues <dbl>,\n#   SpecialDay <dbl>, Month <chr>, OperatingSystems <dbl>,\n#   Browser <dbl>, Region <dbl>, TrafficType <dbl>,\n#   VisitorType <chr>, Weekend <dbl>, Revenue <dbl>,\n#   Informational_Total <dbl>\n\nNext, I wanted to filter and select variables from a data frame.\n\n\nonline_shoppers_select <- online_shoppers_informational %>%\n  filter(Region == \"3\"  & Browser == \"2\") %>%\n  select(`Month`, `VisitorType`, `OperatingSystems`, `Browser`, `Region`)\nonline_shoppers_select\n\n\n# A tibble: 891 x 5\n# Groups:   Month, VisitorType [17]\n   Month VisitorType       OperatingSystems Browser Region\n   <chr> <chr>                        <dbl>   <dbl>  <dbl>\n 1 Feb   Returning_Visitor                2       2      3\n 2 Feb   Returning_Visitor                3       2      3\n 3 Feb   Returning_Visitor                2       2      3\n 4 Mar   Returning_Visitor                2       2      3\n 5 Mar   Returning_Visitor                2       2      3\n 6 Mar   Returning_Visitor                2       2      3\n 7 Mar   Returning_Visitor                2       2      3\n 8 Mar   Returning_Visitor                2       2      3\n 9 Mar   Returning_Visitor                2       2      3\n10 Mar   Returning_Visitor                2       2      3\n# … with 881 more rows\n\nI decided to change the name of the Special Day column to Holiday using the rename function.\n\n\nonline_shoppers_informational <- online_shoppers_informational %>%\n  rename(Holiday = SpecialDay)\n\n\n\nThis is what the SpecialDay column looked like after I changed its name to Holiday.\n\n\n\nLastly with this data frame, I decided to look for duplicate values.\n\n\nduplicated(online_shoppers_select)[1:10]\n\n\n [1] FALSE FALSE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\nThe problem with this approach is the output of duplicated() is a vector and I’d have to search for the values that are TRUE. I would have to index the vector to get the values that are duplicates. This method is not ideal, especially if I’m working with multiple data frames.\nAnother Method of Finding Duplicates\nThere is another way to look for duplicated values. I can combine the duplicated() function with the purrr functionals and dplyr to look for duplicated values.\nFor this example, I’ll use two data frames I created myself.\nThe first step is to create a list of the data frames so I can use a functional to perform the same operation on each data frame.\n\n\nbaby_traffic <- data.frame(Browser = c(\"Windows\", \"macOS\", \"Linux\", \"Android\", \"iOS\"),\n                    Region = c(\"North America\", \"South America\", \"Africa\", \"Asia\", \"South America\"),\n                    TrafficType = c(1, 1, 3, 4, 4))\n\n\nmen_traffic <- data.frame(Browser = c(\"Windows\", \"macOS\", \"Linux\", \"Android\", \"iOS\"),\n                         Region = c(\"Africa\", \"South America\", \"Africa\", \"Asia\", \"Europe\"),\n                         TrafficType = c(0, 2, 1, 3, 0))\n\n\n\n\n\ntraffic <-list(baby_traffic, men_traffic)\n\n\n\nI’ll then use the map() functional and mutate() function to create a new column with the logical output of duplicated(). This will allow me to filter the data frame to return rows where the values of duplicated column are TRUE. When I call dup_traffic, you can see here that duplicates have been identified in the TrafficType column.\n\n\ndup_traffic<- traffic %>%\n  map(mutate, is_dup = duplicated(TrafficType))\ndup_traffic\n\n\n[[1]]\n  Browser        Region TrafficType is_dup\n1 Windows North America           1  FALSE\n2   macOS South America           1   TRUE\n3   Linux        Africa           3  FALSE\n4 Android          Asia           4  FALSE\n5     iOS South America           4   TRUE\n\n[[2]]\n  Browser        Region TrafficType is_dup\n1 Windows        Africa           0  FALSE\n2   macOS South America           2  FALSE\n3   Linux        Africa           1  FALSE\n4 Android          Asia           3  FALSE\n5     iOS        Europe           0   TRUE\n\nI have to admit this was a pretty difficult section but I’m glad I’m learning it! That’s all for Data Cleaning for now. Until next time…\n\n\n\n",
    "preview": "posts/2020-05-29-data-cleaning-with-r/before.jpg",
    "last_modified": "2020-10-15T01:18:06-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-05-28-quick-update/",
    "title": "Quick Update",
    "description": "Quick update on my progress.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-05-28",
    "categories": [
      "data science",
      "programming",
      "R",
      "update"
    ],
    "contents": "\nIt’s been a while since my last post so I wanted to give you a quick update as to what I’ve been up to. Since this whole quarantine my productivity has slowed significantly but I’m taking it one day at a time. I’m working on a few things outside of DataQuest of course.\nFor one, I’m still on the job hunt. I’ve been working on my resume, LinkedIn profile and trying to attend as many virtual meetups as possible in an effort to network.\nAs I mentioned in my last post, I’ve have really become interested in Statistics as of late. I saved some e-books I found on Stats, particularly those that focus on R. I’m also reading of Naked Statistics by Charles Wheelan. I also found a course on Coursera called Statistics in R that I plan on taking in the future.\nI also mentioned that I enrolled in Udacity’s Marketing Analytics Nanodegree. Since then I switched from the Marketing Analytics Nanodegree to the Predictive Analytics Nanodegree. This nanodegree is very challenging though. For one, I do not have the Alteryx software that this course relies heavily on. I could do the projects in Excel (I did the first project in Excel) however, I decided to try to complete the projects using R. This poses a challenge for me as I’m still new to R but it’s a challenge I’m willing to take on. Nonetheless, I’m finding that the topics I’m learning in the Predictive Analytics course falls more in line with my interests. So far I’ve learned about different models: linear regression, multiple linear regression, classification models like logistic regression, decision trees, random forest model and the boosted model. Right now I’m on the A/B Test module which I’m super excited about. I attended the R Ladies Philly virtual meetup where the speaker, Elea McDonnell, discussed A/B Testing in R so I’m especially interested in implementing what I learned in that meetup in my project. The course also includes lessons in SQL and Tableau which I’m also completing.\nI’ve been listening to podcasts and audiobooks. For audiobooks, I’m listening to Bad Blood by John Carreyrou. For podcasts, I’m listening to Naked Beauty Podcast, Techish, Towards Data Science and All the Smoke to name a few. Another book I’m reading is Algorithms of Oppression by Safiya Noble. I recently purchased the kindle version of Data Feminism by Catherine D’Ignazio and Lauren F. Klein.\nI’m very excited about what I’ve been working on and I can’t wait to show you the Udacity projects. That’s all I’ll say for now! Until next time…\n\n\n\n",
    "preview": {},
    "last_modified": "2020-10-13T20:26:15-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-04-08-quarantining-and-things/",
    "title": "Quarantining and Things",
    "description": "What I've been going through in quarantine.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-04-08",
    "categories": [
      "data science",
      "programming",
      "R",
      "quarantine"
    ],
    "contents": "\nIt’s been a minute since I last posted any content on my DataQuest track. So I thought I’d tell you what’s been going on.\nI decided to take a break because I haven’t felt like my productive self. I found myself feeling really sad with all the COVID-19 news. I was unemployed looking for work before this quarantine and I’m still unemployed but now I just feel like, will I ever find a job? On top of this, I felt a bit discouraged about my blog, questioning my abilities, whether or not blogging would actually help me in my transition into a data science career. I constantly asked myself, am I wasting my time? Is all of this in vain? I am also facing difficulty with learning to do data cleaning using R which has slowed me down a bit however, this issue is rather minor compared to the ones I just mentioned.\nHowever, I’m slowly starting to get back to my normal productive self. I continue to learn R using the DataQuest platform. Data cleaning is an essential part of the data analysis process so it’s important to me that I become proficient with this part of the track. One of my blog posts, Scatter Plots, was included in the Code With Veni newsletter which was a huge confidence booster. I nearly cried when I found out my post was included. I can’t explain what an honor it was to be included in a newsletter with other awesome coders. I like to thank DiKayo Data for bringing the newsletter to my attention and Veni for including me. Speaking of Dikayo Data, I participated in her #DataEveryone chat on Tuesday which always lifts my spirits and I leave the chat learning more then when I entered.\nSome of the meetups that I had previously planned to attend are now online and I plan on attending those. I also decided to take advantage of the free month of nanodegrees Udacity announced and enrolled in their Marketing Analytics Nanodegree. It focuses on learning to analyze data and building models with Excel, Data Studio, and creating data visualizations with Tableau. I thought it would be a nice complement to the Data Analyst track which focuses on R and SQL. I’ve already completed the first two sections which focuses on Descriptive Statistics which I really enjoyed.\nI’ve have really become interested in Statistics as of late. I saved some e-books I found on Stats, particularly those that focus on R. I’m also at the beginning of Naked Statistics by Charles Wheelan. I think this interest in Statistics started with my Business Statistics class in undergrad. Back then, I did not understand what was being taught and as a result, did not do well in the class. But I held on to the textbook thinking that one day I would revisit it and teach myself Stats. With Statistics being an important component of Data Science, I figured this is the opportunity to learn it. Everything going on with COVID-19 also has something to do with it. With so much data surrounding this pandemic and this data being in our faces constantly, I want to be able to understand the data and how certain numbers and conclusions are derived. And so here I am revisiting things like standard deviation and variance and learning about correlation and regression.\nI apologize if this sounds like a bunch of random thoughts but I had to get this out. I wanted to share what I’m going through. But the lessons I have learned through all this are that it is okay to not be productive. It’s okay to feel unmotivated. It’s okay to mourn plans that fell through. Especially during these trying times. As for me, I want to use this time to reassesses my habits and goals and I’ve put some thought into life after this crisis. I’m remembering to breathe, take my time and do things at my own pace.\n\n\n\n",
    "preview": {},
    "last_modified": "2020-10-13T20:25:30-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-03-17-analyzing-forest-fire-data/",
    "title": "Project: Analyzing Forest Fire Data",
    "description": "My experience completing my first R project.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-03-17",
    "categories": [
      "data science",
      "programming",
      "R",
      "projects"
    ],
    "contents": "\nI am excited to announce that I have finished the data visualization in R course as part of Dataquest’s Data Analyst track in R. The final assignment in this course was an actual project(my first R project) taking what I’ve learned up until this point to analyze forest fire data from Portugal.\nIt was an interesting project with a few challenges. For one, I had to put the months and days in chronological order to make the charts easier to read. I learned about changing a data type using factor. Once I got the code part down, however, I couldn’t get it to work. It took a while but I finally figured out what happened. I was not executing the code in the right order! Once I figured that out, my code execution went smoothly.\nAnother challenge was finding a place to share the project. I am familiar with Jupyter Notebook and Google Colab for data science projects using Python but was unaware of a similar solution for R. Thanks to the Dataquest community, I learned that I could write my project as a R Markdown and publish it at RPubs. After writing the project as a R Markdown, I tried to publish it but it did not work. Turns out, I needed to install knitr and update XQuartz.\nOnce that was done, I was able to publish my work which you can find in the projects section of this site. Check it out and let me know your thoughts! In the future, I want to publish my code on Github.\nUntil next time…\n\n\n\n",
    "preview": {},
    "last_modified": "2020-10-13T12:28:29-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-03-11-scatterplots/",
    "title": "Scatter Plots",
    "description": "How to create scatter plots in R.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-03-11",
    "categories": [
      "data science",
      "programming",
      "R",
      "scatter plots",
      "exploratory data analysis"
    ],
    "contents": "\nIn the last few posts, I went over different types of plots: line graphs, bar charts, histograms, and box plots. In this post, I’ll go over the scatter plots lesson that is part of DataQuest’s Data Analyst in R track. The DataQuest lesson is called Scatter Plots for Exploratory Analysis.\nThe month of March is Women’s History Month and in honor of Women’s History Month, I decided to use the data sets in the Tidy Tuesday repo called Women in the Workplace. These data sets are about women in the workforce, specifically jobs, employment, and earnings. With that being said let’s go into scatter plots.\nScatter plots represent data using points that have the value of one variable determining the position on the x-axis and the value of the other variable determining the position on the y-axis. Unlike the other plots I’ve studied, scatter plots do not require that values of one variable depend on the values of another variable. Instead, I’m looking for any sort of relationship between the variables.\nThere are different types of relationships between variables. I’ll use variable_x and variable_y as examples here:\nPositive relationship: As the values of variable_x increase, so do the values of variable_y.\nNegative relationship: As the values of variable_x decrease, the values of variable_y increase.\nStrong relationship: Points are clustered together as opposed to being spread out.\nWeak relationship: Points are spread out as opposed to being clustered together.\nNo Relationship: It appears that the points are arranged in a shapeless cloud.\nI can create a scatter plot similar to how I created plots before. However, the layer geom_point() is what creates a scatter plot. Let’s look at an example from a data set I’m working with. The following code and scatter plot look at female earnings by year. As you can see, the format for the ggplot and aes layers are the same as I did with previous plots. The difference is the geom_point() layer which differentiates the scatter plot from other kinds of plots.\n\n\nggplot(data = earnings_female) +\n  aes(x = Year, y = percent) +\n  geom_point()\n\n\n\n\nWhat kind of relationship do the variables have in this example? What can you conclude by looking at this scatter plot?\nInformative Scatter Plots\nThere are a few layers that I could add that would make my plot easier to interpret. As I discussed in my multiple line graphs post, I could adjust my axis ranges. I can specify a scatter plot’s x- and y-axis ranges by adding a separate layer for each to my plot using xlim() and ylim(). In this example, I adjusted the x-axis to show the years 1981 through 2011 and y-axis to specify ranges of 50 through 100.\nYou’ll also notice in this block of code the argument alpha = . This argument makes the points on the plot more transparent. Alpha uses values from 0 through 1 to determine transparency with the value of 0 specifying complete transparency and the value of 1 specifying complete opacity. The intermediate values specify varying degrees of transparency. DataQuest says that alpha values of 0.2 to 0.5 usually will help make overlapping points easier to see.\n\n\nggplot(data = earnings_female) +\n  aes(x = Year, y = percent) +\n  geom_point(alpha = 0.3) +\n  xlim(1981, 2011) +\n  ylim(50, 100) +\n  theme(panel.background = element_rect(fill=\"white\"))\n\n\n\n\nMaking Multiple Scatter Plots Using Functions\nI could create multiple scatter plots by copying and pasting the code block from the second example. However, in programming if you find yourself copying and pasting repeatedly, there is likely a much more efficient solution.\nThis brings us to functions. I could use what I learned about writing custom functions and visualizing data to write a function to create a scatter plot. I could then use my knowledge of functionals to apply my function to the data to create multiple scatter plots at once.\nLet’s look at the code below. I decided to use another data set within the the Women in the Workplace repo that looks at employment for both men and women. However, I decided to focus on the women here.\nAs you can see the code within the function is similar to what I’ve done previously. However instead of using aes() to map variables to axes, I would use aes_string() which allows me to pass vectors of variable names into my function.\nI can then use a functional from the purrr package to apply the create_scatter() function to the variables I want to look at relationships between. In this case, I’m looking for a relationship between year and the percentages of women working part-time and full-time.\nThe create_scatter() function is a two-variable function so I need to use the functional map2(). Recall from my post on functionals that map2() takes two variables as arguments and returns a list.\nSo what kind of output am I looking to obtain with this function? I want to create two scatter plots exploring the following relationships:\nYear and Percentage of Women Working Part-Time\nYear and Percentage of Women Working Full-Time\nI assigned the year variable to the x-axis using x_var. The y-axis will consist of variables I want to compare: part_time_female and full_time_female and I assigned these variables to y_var. In this instance, I decided to type out the names of the variables. However, I could do this another way. I could index the data frame to select specific rows and use the names() function to extract row names.\nThe result of this code are the scatter plots below.\n\n\ncreate_scatter = function(x,y) {\n  ggplot(data = employed_gender) +\n   aes_string(x = x, y = y) +\n   geom_point(alpha = 0.3) +\n    xlim(1970, 2015) +\n    ylim(20, 100) +\n    theme(panel.background = element_rect(fill=\"white\"))\n}\nx_var <- \"year\"\ny_var <-c(\"part_time_female\", \"full_time_female\")\nmap2(x_var, y_var, create_scatter)\n\n\n[[1]]\n\n\n[[2]]\n\n\nWell this just about does it for scatter plots. This was another really fun lesson to work on. The next post will be about a project that covers what I learned thus far. Until next time…\n\n\n\n",
    "preview": "posts/2020-03-11-scatterplots/ScatterPlots_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2020-10-13T20:23:58-04:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2020-03-09-barcharts-histograms-boxplots/",
    "title": "Bar Charts, Histograms, and Box Plots",
    "description": "How to create bar charts, histograms and box plots in R.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-03-09",
    "categories": [
      "data science",
      "programming",
      "R",
      "barcharts",
      "histograms",
      "box plots"
    ],
    "contents": "\nIn the last two posts (Creating Line Graphs and Creating Multiple Line Graphs), I went over creating line charts. To refresh your memory, a line chart is a type of plot used to visualize changes over time. In this post, I’ll go over three more plots that were part of the data visualization mission of DataQuest’s Data Analyst in R track: bar charts, histograms, and box plots.\nFor this post, I decided to continue with the Maryland Bridges data set I used in previous posts.\nSo without further ado, let’s get started!\nBar Charts\nBar charts represent grouped data summaries using bars with heights proportional to values of a summary variable such as average. Like line charts, bar charts depict the relationship between two variables. These charts have an x and y axes; The x-axis represents the independent variable while the y-axis represents the dependent variable.\nTo create a bar chart, I would need the same syntax for the data and aesthetics layers that I used to create line charts. However, this time I need the geom_bar() layer as this layer creates the bar chart.\nLet’s look at an example. I want to create a bar chart that shows the average daily traffic of Maryland bridges by county. As I did in my line chart post, I filtered the data, then added my ggplot() and aes() layers. I add my labs() layer as the last layer.\nAfter the aes layer, you’ll see the geom_bar() layer, which has two arguments: fill, which represents the color of the bars and stat = “identity”. Using stat = “identity” overrides the default behavior of the height of the bars corresponding to the number of values, and instead creates bars equal to the value of the y-variable.\n\n\nbmore_bridges_filter <- bmore_bridges %>% \n  filter (county != \"Baltimore city\", yr_built >= 1900)\n\nggplot(data = bmore_bridges_filter) +\n  aes(x = county, y = avg_daily_traffic) +\n  geom_bar(stat = \"identity\", fill = \"darkgreen\") +\n  labs(title = \"Average Daily Traffic on Maryland Bridges\", x = \"County\", y = \"Average Daily Traffic\")\n\n\n\n\nHistograms\nUnlike a bar chart or a line graph, a histogram is used to understand characteristics of one variable. Histograms depict the distribution of the variable, in other words the frequency with which values of a variable occur.\nTo create the histogram, I would use the layer geom_histogram(). I can specify two different arguments in the geom_histogram() layer to specify the number of categories for binning the independent variable.\nbinwidth = specifies the size of the bins. This is useful for when I want categories to span specific intervals.\nbins = specifies the number of bins. This is useful for experimenting with how much detail I want to use to display my data.\nThe code below is to create a histogram that shows the year the bridges were built and the condition they’re in. After establishing the data and aesthetics layers, I used geom()histogram to create the histogram and I specified the number of bins I want in my histogram. As I did in my line graphs post, I used facet_wrap() to further split the data into subplots based on bridge condition.\nThe histogram below is showing the distribution of all the values of the yr_built variable of my bmore_bridges_filter data frame. On the x-axis is yr_built variable, which represents the year the bridges were built. On the y-axis is a variable that is automatically created when you create a histogram. The count variable represents the number of values of the yr_built variable that fall into each of the categories on the x-axis.\n\n\nggplot(data = bmore_bridges_filter) +\n  aes(x = yr_built) +\n  geom_histogram(bins = 30) +\n  facet_wrap(~bridge_condition, nrow=2)\n\n\n\n\nAs I did with line graphs, I can use color to distinguish between variables within the aes() layer. In the example below, I used the fill= argument, which depicts bars filled in with different colors.\n\n\nggplot(data = bmore_bridges_filter) +\n  aes(x = yr_built, fill = bridge_condition) +\n  geom_histogram(bins = 30) \n\n\n\n\nAlternatively, I could use the color= argument which maps my specified variable to bar outlines of different colors. Check out the example below and note the difference between color and fill.\n\n\nggplot(data = bmore_bridges_filter) +\n  aes(x = yr_built, color = bridge_condition) +\n  geom_histogram(bins = 30) \n\n\n\n\nBox Plots\nBox plots provide a summary of data for each group and provide information about how the data is spread. I would add the geom_boxplot() layer to create a box plot. Box plots present data in what is known as the five-number summary. The five numbers refer to percentiles of the data I’m working with. The five percentiles summarized by a box plot are the following:\nThe largest value: Represented by the top of the black line extending from the top of the box. These are also known as “whiskers”.\nThe third quartile(Q3): Represented by the top of the box. Seventy-five percent of the values are smaller than the third quartile.\nThe median: Represented by a thick black line. The median is the value that falls int he middle of the data.\nThe first quartile(Q1): Represented by the bottom of the box. Twenty-five percent of the values are smaller than the first quartile.\nThe smallest value: Represented by the bottom of the black line extending from the bottom of the box.\nThe example below shows the code used to create a box plot. With the exception of the geom_boxplot() layer, it’s pretty much the same thing I’ve done with plots I previously went over.\n\n\nggplot(data = bmore_bridges_filter) +\n  aes(x = bridge_condition, y = yr_built) +\n  geom_boxplot() +\n  theme(panel.background = element_rect(fill = \"white\")) +\n  labs(title = \"Conditions of Maryland Bridges Over Time\", x = \"Bridge Condition\", y = \"Year\")\n\n\n\n\nWhen creating a box plot, you’ll sometimes notice some points that fall below the bottom of the black lines that represent the smallest value. These points are known as outliers because they are outside the range of would be expected based on the rest of the data.\nI am really enjoying learning experimenting and visualizing using different types of plots. Looks like I’m going to have to brush up on statistics to gain a deeper understanding of how this all works.\nI can’t wait until I am able to do this in a work environment. Well that’s all for this section! Until next time…\n\n\n\n",
    "preview": "posts/2020-03-09-barcharts-histograms-boxplots/BarChartsHistogramsBoxPlots_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2020-10-13T20:23:15-04:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2020-02-28-creating-multiple-line-graphs/",
    "title": "Creating Multiple Line Graphs",
    "description": "How to create multiple line graphs in R.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-02-28",
    "categories": [
      "data science",
      "programming",
      "R",
      "multiple line graphs"
    ],
    "contents": "\n\n    pre code {\n      white-space: pre-wrap;\n    }\nIn the previous post, I created a single line graph using the tidyverse package called ggplot2 and the data set I found on Tidy Tuesday’s github repo called Maryland Bridges that explored bridge conditions in Maryland.\nI will continue to use that data set in this post while getting into the next lesson of DataQuest’s Data Analyst in R track, Creating Multiple Line Graphs in R. So let’s get started!\nMultiple Panels\nOne way to improve clarity of a line graph is to plot data on different axes using multiple graph panels. I can create line graphs on multiple, adjoining panels from the same data set by adding a new layer to my graph: facet_wrap(). The facet_wrap() function splits data into subplots based on the values of a variable in my data set. I could use the ncol= or nrow= arguments to specify the number of columns or rows of panels in my visualization.\nIn the line graph example below, Average Daily Traffic on Maryland Bridges(Over Time), I filtered out the county variable that contained the alternate spelling of “Baltimore city” and years that were less than 1900. After creating a plot, I used facet_wrap() to further split the data into subplots based on county. I specified that I wanted two columns of panels in my data viz.\n\n\nbmore_bridges_filter <- bmore_bridges %>% filter(county != \"Baltimore city\", yr_built >= 1900)\n\nggplot(data = bmore_bridges_filter) +\n  aes(x = yr_built, y = avg_daily_traffic) +\n  geom_line() + \n  labs(title = \"Average Daily Traffic on Maryland Bridges Over Time\", x = \"Year\", y = \"Average Daily Traffic\") +\n  facet_wrap(~county, ncol = 2)\n\n\n\n\nDifferent Line Types and Colors\nLet’s say I want to create a line graph with different values of a variable showing different styles of lines. I can plot multiple lines within the aes() layer using the lty argument. The argument lty stands for “line type” and its syntax is lty=. From the photos below, I can see that a line graph was created with different values of the county variable using different line types. Notice how this creates a legend, a box containing information about which line type matches which value of the county variable.\n\n\nggplot(data = bmore_bridges_filter) +\n  aes(x = yr_built, y = avg_daily_traffic, lty=county) +\n  geom_line() + \n  labs(title = \"Average Daily Traffic on Maryland Bridges Over Time\", x = \"Year\", y = \"Average Daily Traffic\")\n\n\n\n\nIn addition to line type, I could differentiate lines for different values of a variable using color. I could use the argument color = to show different values of the county variable using different colors.\n\n\nggplot(data = bmore_bridges_filter) +\n  aes(x = yr_built, y = avg_daily_traffic, color = county) +\n  geom_line() + \n  labs(title = \"Average Daily Traffic on Maryland Bridges Over Time\", x = \"Year\", y = \"Average Daily Traffic\")\n\n\n\n\nScale Limits\nWhat if I want to hone in on a subset of data? Let’s say I want to hone in on bridges built between 1950-1990. This is where I would set scale limits. Scale limits refer to changing the ranges of my axes so I could only display a portion of my data. Adding the xlim() (changes x-axis) and ylim() (changes y-axis) layers to my graph allows me to display a subset of my data. In the case below, I use xlim() to change the range of my x-axis to display the years between 1950-1990.\n\n\nggplot(data = bmore_bridges_filter) +\n  aes(x = yr_built, y = avg_daily_traffic, color = county) +\n  geom_line() + \n   xlim(1950, 1990) +\n  labs(title = \"Average Daily Traffic on Maryland Bridges Over Time\", x = \"Year\", y = \"Average Daily Traffic\")\n\n\n\n\nManipulating Aesthetics\nIf I want to manually change the colors of my graph, I would add another layer called scale_color_manual(). The code and photo of my graph below show that I used this layer to change the colors of the values of my county variable. To manually change the line types representing bridge_condition, I would use the layer, scale_linetype_manual(). As noted in the photo below, I decided to have three line types: solid, longdash, and twodash.\n\n\nggplot(data = bmore_bridges_filter) +\n  aes(x = yr_built, y = avg_daily_traffic, color = county, lty= bridge_condition) +\n  geom_line() + \n  scale_color_manual(values = c(\"darkgoldenrod4\", \"darkslategrey\", \"chocolate3\", \"darkorchid\", \"darkgreen\", \"darkcyan\")) +\n  scale_linetype_manual(values= c(\"solid\", \"longdash\", \"twodash\"))  +\n  labs(title = \"Average Daily Traffic on Maryland Bridges Over Time\", x = \"Year\", y = \"Average Daily Traffic\")\n\n\n\n\nI want to share the resources for manipulating colors and line types in R that DataQuest shared in this portion of the lesson.\nColor guide\nLine Type guide\nThough I’m still new to this whole data visualization in R, I can honestly say that this is really fun. I’m enjoying experimenting with aesthetics and the different ways to present information in a graph. I’m going to keep practicing and experimenting with aesthetics and learning about different plots. Until next time…\n\n\n\n",
    "preview": "posts/2020-02-28-creating-multiple-line-graphs/CreatingMultipleLineGraphs_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2020-10-13T20:22:14-04:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2020-02-24-creating-line-graphs/",
    "title": "Creating Line Graphs",
    "description": "How to create line graphs in R.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-02-24",
    "categories": [
      "data science",
      "programming",
      "R",
      "line graphs"
    ],
    "contents": "\n\n    pre code {\n      white-space: pre-wrap;\n    }\nI have now reached the data visualization course in DataQuest’s Data Analyst in R track. I am really excited to have reached this point because I’ve always wanted to try visualizing data. One thing I like about data visualization is that it easier to identify patterns in data and plan analyses.\nThroughout this course, I’ll be using a very popular tidyverse package called ggplot2. I follow the #rstats and #TidyTuesday hashtags on Twitter and ggplot2 is a package that I’ve seen discussed A LOT when it comes to data visualization in R. DataQuest attributes its popularity to its consistent syntax and the efficiency with which you can use to create quality data visualizations.\nIn this post, I am using yet another data set I found on Tidy Tuesday’s github repo. This data set explores bridges in the state of Maryland. Before I started with the lesson I made sure to load the tidyverse package, which includes gglplot2 and import the data, saving the data into a data frame called bmore_bridges. As shown in the screenshot below, I then filtered the data frame to only contain bridges owned by the State Highway Agency.\n\n\nbmore_bridges_filter <- bmore_bridges %>% filter(owner == \"State Highway Agency\")\nbmore_bridges_filter\n\n\n# A tibble: 913 x 13\n     lat  long county carries yr_built bridge_condition\n   <dbl> <dbl> <chr>  <chr>      <dbl> <chr>           \n 1  39.2 -76.7 Anne … IS 695      1958 Fair            \n 2  39.2 -76.7 Anne … IS 695      1951 Fair            \n 3  39.2 -76.6 Anne … IS 695…     1957 Fair            \n 4  39.2 -76.6 Anne … IS 695…     1957 Fair            \n 5  39.2 -76.6 Anne … MD 2        1937 Good            \n 6  39.1 -76.6 Anne … MD 2        1936 Fair            \n 7  39.0 -76.5 Anne … MD 2 R…     1953 Good            \n 8  39.0 -76.5 Anne … US 50 …     1953 Fair            \n 9  39.0 -76.6 Anne … MD 2        1983 Fair            \n10  39.2 -76.7 Anne … MD 168      1949 Fair            \n# … with 903 more rows, and 7 more variables:\n#   avg_daily_traffic <dbl>, total_improve_cost_thousands <dbl>,\n#   inspection_mo <chr>, inspection_yr <dbl>, owner <chr>,\n#   responsibility <chr>, vehicles <chr>\n\nThe first lesson in this course is about creating line graphs. The first topic that I went over was using plots to visualize data patterns. Plots are visual representations that use graphics like dots, lines, and bars to help you look for patterns in data. There are many kinds of plots I can use to visualize data. In this lesson, I used a line chart which is a type of plot that is especially useful for visualizing changes over time.\nggPlot2\nSo what’s the history behind ggplot2? Hadley Wickham, the chief data scientist at RStudio developed ggplot2 based on “Grammar of Graphics”. Grammar of Graphics, by Leland Wilkinson, refers to a system for data visualization.\nNow that we know a bit of the history, I want go over step-by-step how I created my line chart.\nFirst, I begin to make a plot using the ggplot() function and specify the data frame I’ll be visualizing from. This step is the foundation in creating a coordinate system that I can add layers to. When I type the code below, I’ll get a graphic of an empty plot.\n\n\nggplot(data = bmore_bridges_filter)\n\n\n\n\nNote: DataQuest notes that while I do not have to assign the data frame to the variable data, they recommend doing so as I learn ggplot(). It helps keep track of the different functions used to build data visualizations.\nAesthetics\nThe second step is to define the variables I want to map on my graph. To do this, I use the aes() function, which stands for aesthetics. Because I’m graphing dimensional data, my graph will have two axes: an x-axis and a y-axis. As shown here, I assigned the county variable to x and the avg_daily_traffic to y.\n\n\nggplot(data = bmore_bridges_filter) +\n  aes(x = county, y = avg_daily_traffic)\n\n\n\n\nBut how do I know which axis to use for which variable? Let me explain.\nThe variable that changes depending on another variable is called the dependent variable. This variable is assigned to the vertical axis, or y-axis. In the example above, avg_daily_traffic is the dependent variable because it changes depending on the county.\nThe variable that changes independent of another variable is called the independent variable. This variable is assigned to the horizontal axis, or x-axis. In this case, county is the independent variable because its changes do not depend on another variable.\nAlso, from the photo shown there is a plus sign added at the end of the ggplot() function. To add new layers to the graph, a plus sign is needed followed by another layer.\nAdding Geometric Objects to Visualize Data Points\nThe third step is to add geometric symbols to the graph to represent data points. As shown below, I added the geom_line() layer to my graph to add a line representing the relationship between the county and avg_daily_traffic variables.\n\n\nggplot(data = bmore_bridges_filter) +\n  aes(x = county, y = avg_daily_traffic) +\n  geom_line() \n\n\n\n\nThere are many types of geometric objects I could add to a graph depending on what type of data I’m working with the relationship between variables I’m looking to explore. But for this post, I focused on adding a line to visualize the data.\nAdding Graph Titles and Axis Labels\nI want to make my graph easier to understand. This is where adding graph titles and changing axis labels come in. The labs() layer, which is short for labels, is the next layer I added to my graph. I specified the title of my graph using title = , the x-axis , and the y-axis all inside the labs() argument. The titles and labels of a graph should be descriptive and clearly communicate the type of data used in the graph.\n\n\nggplot(data = bmore_bridges_filter) +\n  aes(x = county, y = avg_daily_traffic) +\n  geom_line() +\n  labs(title = \"Condition of Bridges owned by State Highway Agency\", x= \"County\", y =\"Average Daily Traffic\")\n\n\n\n\nRefining Graph Aesthetics\nSo, I want to change the background color of my graph to white. To do this, I add another layer to my graph using the theme() layer. The theme() layer is used to modify non-data ggplot2 graph components. The argument panel.background = element_rect, specifies the color of the background rectangle(“rect” stands for rectangle). I then use fill = to specify that I want a white background.\nThe Final Result\nWhen I run the following code, I get the following plot below. This is a basic, bare bones line chart but its clear and informative(I think). From this plot, I can see that Baltimore County has the highest average daily traffic and Carroll County has the lowest average daily traffic.\n\n\nggplot(data = bmore_bridges_filter) +\n  aes(x = county, y = avg_daily_traffic) +\n  geom_line() +\n  labs(title = \"Condition of Bridges owned by State Highway Agency\", x= \"County\", y =\"Average Daily Traffic\") +\n  theme(panel.background = element_rect(fill = 'white'))\n\n\n\n\nThe End\nI can’t tell you enough how I excited I was about this part of the course. When I would look at #TidyTuesday posts, I would marvel at the creations people came up with. Though if I’m being honest, I was intimidated by the code. The more I code in R, the more I read others’ R code, the less intimidating the code is. I knew that I wanted to start creating cool data visualizations like the ones I admired. With these R lessons, I’m on my way to doing just that.\nWell, that’s all I got for this lesson! Until next time…\n\n\n\n",
    "preview": "posts/2020-02-24-creating-line-graphs/CreatingLineGraphs_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2020-10-13T20:20:56-04:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2020-02-21-fundamentals-of-string-manipulation/",
    "title": "Fundamentals of String Manipulation",
    "description": "String manipulation in R.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-02-21",
    "categories": [
      "data science",
      "programming",
      "R",
      "string manipulation"
    ],
    "contents": "\nIn previous posts, I’ve worked with variables with numerical data. This post will focus on working on variables with character data. The data set that I am using for this post was posted on Tidy Tuesday’s Github. This data set comes from Spotify and provides information about popular songs and their genres. So let’s get started!\nSubsetting a String\nIn this lesson, I worked with a tidyverse package called stringr. The stringr package contains tools for combining, splitting, adding, and removing spaces from, and other performing other useful string data manipulations. Functions in the stringr package all begin with the prefix str_ and RStudio’s autocomplete feature makes this package especially fun to work with!\nI’ll first discuss a function I learned can subset strings, str_sub(). The str_sub function takes a string, subsets it based on positions of characters within the string, and returns a new string containing only the characters between the specified positions. The string that’s returned includes the characters of the positions specified as well as those between them. All characters are included, even spaces.\nLet’s look at an example. I am working with the data frame called spotify_songs and I want to subset the track_artist variable and return a new vector consisting of the first nine letters of each artist. I indexed the track_artist variable to include only the first twenty artists. I then subset the variable from left to right by position with 1 and 9 representing the position numbers.\n\n\nstr_sub(spotify_songs$track_artist[1:10], 1, 9)\n\n\n [1] \"Ed Sheera\" \"Maroon 5\"  \"Zara Lars\" \"The Chain\" \"Lewis Cap\"\n [6] \"Ed Sheera\" \"Katy Perr\" \"Sam Feldt\" \"Avicii\"    \"Shawn Men\"\n\nI can see here that the function resulted in a return of strings with only the characters between the specified positions.\nTo subset the same track_artist variable from right to left by position, I use a minus sign (–) before the position number, like so:\n\n\nstr_sub(spotify_songs$track_artist[1:10], -9, -1)\n\n\n [1] \"d Sheeran\" \"Maroon 5\"  \"a Larsson\" \"insmokers\" \"s Capaldi\"\n [6] \"d Sheeran\" \"aty Perry\" \"Sam Feldt\" \"Avicii\"    \"wn Mendes\"\n\nNote that the sub_str() function is vectorized. I could apply it to a vector and it will return a new vector.\nSplitting A String\nAnother technique for subsetting strings is splitting strings using the str_split() function. Unlike the str_sub() function, the str_split() function is not dependent on position. The str_split() function is used to split a string into pieces. The place where the string is split is called the delimeter. The delimeter refers to a space, comma, another character or characters.\nLet’s look at what happens when I use the str_split() function to split the strings listed in the first example.\n\n\nartist_match <-str_sub(spotify_songs$track_artist[1:6], 1, 9)\nstr_split(artist_match, \" \")\n\n\n[[1]]\n[1] \"Ed\"     \"Sheera\"\n\n[[2]]\n[1] \"Maroon\" \"5\"     \n\n[[3]]\n[1] \"Zara\" \"Lars\"\n\n[[4]]\n[1] \"The\"   \"Chain\"\n\n[[5]]\n[1] \"Lewis\" \"Cap\"  \n\n[[6]]\n[1] \"Ed\"     \"Sheera\"\n\nartist_match[1:6]\n\n\n[1] \"Ed Sheera\" \"Maroon 5\"  \"Zara Lars\" \"The Chain\" \"Lewis Cap\"\n[6] \"Ed Sheera\"\n\nFrom the photos, I can see that the string split occurred where there is a space. I can also see that by default the output is a list.\nI can use the simplify = TRUE argument to simplify the output into a matrix, like so:\n\n\nartist_match_split <-str_split(artist_match, \" \", simplify = TRUE)\nartist_match_split[1:6]\n\n\n[1] \"Ed\"     \"Maroon\" \"Zara\"   \"The\"    \"Lewis\"  \"Ed\"    \n\nCombining Strings\nThe function for combining strings is called str_c().\nI’ll use str_c() to combine multiple strings from my spotify_songs data frame into a single variable.\nLet’s see what happens when I combine the variables track_name and track_artist into one variable.\n\n\nstr_c(spotify_songs$track_name[1:6], spotify_songs$track_artist[1:6])\n\n\n[1] \"I Don't Care (with Justin Bieber) - Loud Luxury RemixEd Sheeran\"\n[2] \"Memories - Dillon Francis RemixMaroon 5\"                        \n[3] \"All the Time - Don Diablo RemixZara Larsson\"                    \n[4] \"Call You Mine - Keanu Silva RemixThe Chainsmokers\"              \n[5] \"Someone You Loved - Future Humans RemixLewis Capaldi\"           \n[6] \"Beautiful People (feat. Khalid) - Jack Wins RemixEd Sheeran\"    \n\nI can use the sep= argument within the str_c() function to specify characters to place between the strings I’m combining.\n\n[1] \"I Don't Care (with Justin Bieber) - Loud Luxury Remix Ed Sheeran\"\n[2] \"Memories - Dillon Francis Remix Maroon 5\"                        \n[3] \"All the Time - Don Diablo Remix Zara Larsson\"                    \n[4] \"Call You Mine - Keanu Silva Remix The Chainsmokers\"              \n[5] \"Someone You Loved - Future Humans Remix Lewis Capaldi\"           \n[6] \"Beautiful People (feat. Khalid) - Jack Wins Remix Ed Sheeran\"    \n\nPadding A String\nThis is where I deviated from DataQuest a bit. After reading this section of the lesson, I was a bit confused. So I decided to do some research and came across this tidyverse documentation describing how to pad a string.\nThe stringr function, str_pad() lets me specify characters into an existing string to make it a specified length.\nThe function takes as arguments:\nThe string you’re working with\nThe minimum width of padded strings\nThe side on which padding is added Single character padding (space is the default)\nTo better understand the str_pad() function and its arguments, I took this screenshot of the tidyverse documentation.\nStringr DocumentationI have a few examples where I experimented with padding strings.\n\n\nstr_pad(\"Zara Larsson\", c(8, 16, 24))\n\n\n[1] \"Zara Larsson\"             \"    Zara Larsson\"        \n[3] \"            Zara Larsson\"\n\n\n\nstr_pad(c(\"Ed Sheeran\", \"Maroon 5\", \"Zara Larsson\"), 10)\n\n\n[1] \"Ed Sheeran\"   \"  Maroon 5\"   \"Zara Larsson\"\n\n\n\nrbind(\n  str_pad(\"Ed Sheeran\", 20, \"left\"),\n  str_pad(\"Maroon 5\", 20, \"right\"),\n  str_pad(\"Zara Larsson\", 20, \"both\")\n)\n\n\n     [,1]                  \n[1,] \"          Ed Sheeran\"\n[2,] \"Maroon 5            \"\n[3,] \"    Zara Larsson    \"\n\nI can check the length of the strings in my vector using the str_length function. The str_length function returns a vector containing the number of characters in each string.\nFor example, I took the strings from one of my str_pad() functions and called the str_length() function on them, I got the following result.\n\n\nstr_length(\"Maroon 5\")\n\n\n[1] 8\n\n\n\nstr_length(\"Ed Sheeran\")\n\n\n[1] 10\n\n\n\nstr_length(\"Zara Larsson\")\n\n\n[1] 12\n\nI can see that the “Ed Sheeran” string has 10 characters, the “Maroon 5” string also has 8 characters, and “Zara Larsson” has 12 characters.\nThat just about covers it for string manipulation. This was a fun lesson! This lesson also marks the end of the Intermediate R Programming course in the Data Analyst in R track. I’m moving on to data visualization! Until next time…\n\n\n\n",
    "preview": {},
    "last_modified": "2020-10-13T20:20:10-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-02-19-functionals/",
    "title": "Functionals",
    "description": "Functionals in R.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-02-19",
    "categories": [
      "data science",
      "programming",
      "R",
      "functionals"
    ],
    "contents": "\n\n  pre code {\n    white-space: pre-wrap;\n  }\nIn a previous post, I went over vectorized functions in R. Vectorized functions are used to operate on all the elements of a vector at once. However, not all functions in R can be applied to all of the elements of a vector at once.\nAs another alternative to for-loops, I could use R’s functionals. A functional is a function that takes a function as an input and returns a vector as an output. DataQuest explains that in many situations, functionals eliminate the need for for-loops by allowing me to apply any function to all elements of a list or vector.\nFor this post, I decided to play around with a data set I found on Tidy Tuesday’s Github. The data set is about wine ratings and I thought it awesome to create a wine-themed post this week.\nFunctionals Using The Tidyverse Purrr Package\nBase R includes a family of functionals known as the “apply” family. These functionals allow me to apply functions to elements of an object. However, the apply functions can be cumbersome to use due to its inconsistency in syntax and output.\nInstead, DataQuest introduces me to the purrr package. The purrr package can be used for the same purposes as the apply family of functionals, and its consistency in syntax and output makes it easier to use and my code more legible.\nI am then introduced to the purrr functional map(), DataQuest explains that the map() functional takes a vector or a list, applies a single-variable function to its elements, and returns a list. Let’s look at an example of this:\nI created a list of points and prices of wines. Here is what the list looks like.\nI found the lowest number in each pair of numbers by applying the min() function to each pair in the list wine_results. To use the map () functional, I would include the vector or list (wine_results) of data and the function (min) as arguments. I saved this to min_results. When I call min_results, I get this list below.\n\n\nwine_results<-list(c(87, 15), c(84, 35), c(91, 95), c(96, 54), c(100, 350))\nnames(wine_results)<-c(\"Portuguese Red\", \"Carignan\", \"Merlot\", \"Pinot Noir\", \"Muscat\")\nmin_results<-map(wine_results, min)\nmin_results\n\n\n$`Portuguese Red`\n[1] 15\n\n$Carignan\n[1] 35\n\n$Merlot\n[1] 91\n\n$`Pinot Noir`\n[1] 54\n\n$Muscat\n[1] 100\n\nUsing Functionals to Apply Custom Functions\nI could use map() to apply a function to multiple variables of my data frame. Let’s say I want to apply my avg_wine_result function to the points and price variables in the wine_ratings data frame. I could use select() to choose the variables you wanted to work with and map() to apply the function to them. In this case, I could install and load the purrr and dplyr packages separately. However, I already have tidyverse(installing tidyverse includes both purrr and dplyr) installed so I just loaded tidyverse using the library() function.\n\n\navg_wine_result <- function(x) {\n  mean(x, na.rm = TRUE)  \n}\nper_wine<-wine_ratings %>% select(points, price) %>% map(avg_wine_result)\n\nper_wine\n\n\n$points\n[1] 88.44714\n\n$price\n[1] 35.36339\n\nThe map() functional applies the avg_wine_result() function to each element of the scores data frame — the points and price variable vectors. The result is a list of output vectors for each variable. Note that map() always returns a list.\nThough I used two variables in this example, this approach would scale well if I decided to apply a single-variable function to a much larger list of variables.\nNote: I used na.rm = TRUE to exclude missing values when taking the mean of x. You can learn more about that here.\nUsing Functionals To Return Vectors of Specified Types\nAs I mentioned, map() always returns a list. But what if I want to specify an output of a different type?\nThe purrr package contains variants of the map() functional, which allow me to return a vector consisting of output of the specified data type. The following are four variants that I learned about in this lesson:\nmap_lgl() returns a logical vector\nmap_int() returns an integer vector\nmap_dbl() returns a double vector\nmap_chr() returns a character vector\nNote that in R integer and double data types are subsets of the numeric data type.\nLet me show an example. Recall the wine_results list from an earlier example. I used the map_dbl functional to apply the sum() to the wine_results list. The result is a vector of double values with the name attributes retained:\n\n\nwine_results<-list(c(87, 15), c(84, 35), c(91, 95), c(96, 54), c(100, 350))\nnames(wine_results)<-c(\"Portuguese Red\", \"Carignan\", \"Merlot\", \"Pinot Noir\", \"Muscat\")\nsum_dbl<-map_dbl(wine_results, sum)\nsum_dbl\n\n\nPortuguese Red       Carignan         Merlot     Pinot Noir \n           102            119            186            150 \n        Muscat \n           450 \n\n\n\ntypeof(sum_dbl)\n\n\n[1] \"double\"\n\nFunctionals for Two-Variable Functions\nSo far, I’ve talked about using the map() functional to apply any single-variable function to elements of a list or vector. But what about functions with more than one variable?\nWhen applying a function with two variables, I’ll need to use a different functional from the purrr package: map2(). The map2() functional takes two variables and a function as arguments and returns a list. Take a look at the example in the screenshot below.\nThe x list represents the points of the wine and the y list represents the prices of the wines. I want to calculate the proportion between points and prices. I then write a function to calculate the proportion. Next, I use the map2() functional to apply the proportion_of_total function to my x and y lists. The result is a list of the output.\n\n\nx <- list(87, 84, 91, 96, 100)\ny <- list(15, 35, 95, 54, 350)\n\nproportion_of_total <- function(x,y) {\n  if(x + y > 0){\n    total = x + y\n    (x/total)\n  }else{\n    0\n  }\n}\n\nmap2(x, y, proportion_of_total)\n\n\n[[1]]\n[1] 0.8529412\n\n[[2]]\n[1] 0.7058824\n\n[[3]]\n[1] 0.4892473\n\n[[4]]\n[1] 0.64\n\n[[5]]\n[1] 0.2222222\n\nAs with the map() functional, the purrr package includes variants of the map2() functional which are:\nmap2_lgl() returns a logical vector\nmap2_int() returns an integer vector\nmap2_dbl() returns a double vector\nmap2_chr() returns a character vector\nThe screenshot below demonstrates the map2_chr() functional using the above example.\n\n\nmap2_chr(x,y,proportion_of_total)\n\n\n[1] \"0.852941\" \"0.705882\" \"0.489247\" \"0.640000\" \"0.222222\"\n\nFunctionals For Functions with More Than Two Variable Arguments\nAs I mentioned before, functions can take more than two variables as arguments. How would I apply a function with more than two variables to a list and return a list? The purrr package contains a functional called pmap(), which works for functions with any number of variables as arguments.\nTake a look at the screenshot below. This time I have three lists: x represents points, y represents price and z represents id numbers. I created a new list, total_list, containing the variables I’m working with. This new total list is created because when working with the pmap() functional, function arguments are provided as a list. Once I created this new list, I created the main_total function. I could then apply the function to the total list I created.\nAs you see in the screenshot, the result of pmap() returns a list.\n\n\nx <- list(87, 84, 91, 96, 100)\ny <- list(15, 35, 95, 54, 350)\nz <- list(1, 13609, 168, 15845, 345)\n\ntotal_list <-list(x, y, z)\nmain_total <- function(x,y,z) {\n  if(x <=100){\n    y+3\n  }else{\n    z -10\n  }\n}\npmap(total_list, main_total)\n\n\n[[1]]\n[1] 18\n\n[[2]]\n[1] 38\n\n[[3]]\n[1] 98\n\n[[4]]\n[1] 57\n\n[[5]]\n[1] 353\n\nAs with the map() and map2() functionals, the purrr package also includes variants of the pmap() functional which are:\npmap_lgl() returns a logical vector\npmap_int() returns an integer vector\npmap_dbl() returns a double vector\npmap_chr() returns a character vector\nThe screenshot below demonstrates the pmap_chr() functional using the above example.\n\n\npmap_chr(total_list, main_total)\n\n\n[1] \"18.000000\"  \"38.000000\"  \"98.000000\"  \"57.000000\"  \"353.000000\"\n\nWell, that was it for functionals. I must admit that I struggled with map2() and pmap() functionals. It took a while for me to get them working in R Studio. However, I am so happy that I got them working and was able to share what I learned with you. Until next time…\n\n\n\n",
    "preview": {},
    "last_modified": "2020-10-13T20:18:52-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-02-12-custom-functions/",
    "title": "Custom Functions",
    "description": "Custom functions in R.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-02-12",
    "categories": [
      "data science",
      "programming",
      "R",
      "custom functions"
    ],
    "contents": "\n\n  pre code {\n    white-space: pre-wrap;\n  }\nThis post will go over DataQuest’s Writing Custom Functions lesson. I decided to continue with the movie-theme in honor of the Academy Awards that took place on Sunday. I will continue to use the data set from my previous vectorized functions post. The data set comes from Kaggle and was composed by a Kaggle member with the user name of kikun1234. It explores award nominations of movies released between 2000-2018. Like I did in the last post, I loaded the tidyverse library and loaded the data set into a data frame called oscars_2018.\nSo without further delay, let’s get started!\nThere are times where base R functions and functions that are part of a package will not do. If I find myself copying and pasting the same blocks of code repeatedly to perform a task, it’s best to streamline my workflow and write a function. I learned that pre-written R functions are written in a complied language and have an R “wrapper” that I as a user interact with. With this DataQuest lesson, I gained a deeper understanding of how functions work.\nI want to begin with the components of an R function. In R, the components of a function consists of the following:\nBody: The code inside the function.\nArguments: The list of inputs that control how the function is called.\nEnvironment: The location where the function was created.\nLet me show you an example. As shown here, the name of this function is multiply_2. The name of the function should ideally describe what the function does. The x represents the data the function is being applied to, or the function argument. The x * 2 represent the body of the function. In this case, I want to multiply the values of the popularity variable of my data set by 2. I then decided to save it to a vector called double_popularity. The value returned by a function will be whatever the output of the last line that got executed is. This happens by default.\n\n\nmultiply_2 <-function(x) {\n  x * 2\n}\ndouble_popularity<-multiply_2(x=oscars_2018$popularity)\ndouble_popularity[1:10]\n\n\n [1] 4726 5718 3752 5016  408 4306  710 1310 2664 4044\n\nIn R, functions are objects. Once they are created, they are stored in the environment you created them in. The following screenshot shows me where the functions created in the global environment in R Studio.\nGlobal Environment in R StudioDataQuest does a very good job of detailing how the local and global environment work when calling a function. Because I can’t say it better myself, I’ll just leave their explanation here:\n\n“When you call a function, the function executes in its own local environment\nwhich consists of a temporary copy of everything in the global environment plus\nwhatever data was passed to the function as arguments. When the function\nfinishes executing, the returned value is placed in the environment you called\nthe function in, and the function’s local environment is discarded.”\n\nI can call this function in a multiple ways: I could have done:\nmultiply_2(2)\nmultiply_2(x=2)\nHowever, here I decided to the multiply_2 function on a vector. That would be the popularity variable of the oscars_2018 data frame.\nWriting Functions with Two Arguments As Arguments\nThe example above is a function written with one argument. However, functions can take on multiple variables as arguments. There are some instances where a function requires multiple variables. Let’s say I wanted to calculate the averages of the user_reviews and critic_reviews variables in my data set. Then, add them together. I would write the following:\n\n\naverage_reviews <- function(x,y) {\n  mean(x) + mean(y)\n}\n\nuser_critic_reviews <- average_reviews(x = oscars_2018$user_reviews, y=oscars_2018$critic_reviews)\n\nuser_critic_reviews\n\n\n[1] 825.2656\n\nAs shown here, I assigned x to user_reviews and y to critic_reviews. I took the average of each variable, then added them together.\nWriting Functions with More Than Two Arguments\nFunctions can take any number of arguments. Here, I will demonstrate a function taking three arguments. Let’s say I wanted to write a function to calculate the sum of two numbers(x,y) and divide the sum by a third number(z). I’ll call these variables, x, y, and z respectively.\nx will represent user_reviews\ny will represent critic_reviews\nz will represent metascore\nI want to add up the reviews for the The Lord of the Rings movie and divide the sum by the movie’s Metacritic score. I would write the following:\n\n\naverage_reviews_one<-function(x,y){\n  if (x+y > 0) {\n    mean(x) + mean(y)\n  }else {\n    0\n  }\n} \n\naverage_reviews_one(x=oscars_2018$user_reviews[5], y=oscars_2018$critic_reviews[5])\n\n\n[1] 5374\n\nThe number five represents the position the Lord of Rings movie is in my data set.\nThis wraps up my writing custom functions post, I’ll admit that this was one of the more difficult posts to write in the beginning because I’m still wrapping head around the topic and the whole local/global environment concept.\nBut I thank you taking the time to read my posts and be on the look out for my next post! Until next time…\n\n\n\n",
    "preview": {},
    "last_modified": "2020-10-13T20:17:03-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-02-10-vectorized-functions/",
    "title": "Vectorized Functions",
    "description": "Vectorized Functions in R.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-02-10",
    "categories": [
      "data science",
      "programming",
      "R",
      "vectorized functions"
    ],
    "contents": "\n\n    pre code {\n      white-space: pre-wrap;\n    }\nIn my last post, I went over for-loops. For-loops are a common programming task and it’s important in understanding how programming works. However, in R for-loops are not written as often as it is for other programming languages.\nMany of R’s built-in functions contain for-loops. One could say that many R functions serve as an alternative to for-loops. Many R functions are vectorized meaning that you can use them to operate on all the elements of a vector quickly. Some of these functions, like sum() and mean() for example, I’ve covered in previous posts. Using vectorized functions not only makes code easier to understand, but its run time is faster than for-loops. As DataQuest explains, this is because applying the function to the entire vector allows R to interpret the input and pass it to the compiled code once.\nThis post will go over DataQuest’s Working With Vectorized Functions lesson. I decided to make this post movie-themed in honor of the Academy Awards that took place last night. The data set I will use in this post comes from Kaggle and was composed by a Kaggle member with the user name of kikun1234. It explores award nominations of movies released between 2000-2018. I loaded the data set into a data frame called oscars_2018. So without further delay, let’s get started!\nI already loaded the tidyverse package and imported our data.\nNow I am printing our dataset as a tibble.\n\n\nprint(as_tibble(oscars_2018[1:10]))\n\n\n# A tibble: 1,235 x 10\n    year movie movie_id certificate duration genre  rate metascore\n   <dbl> <chr> <chr>    <chr>          <dbl> <chr> <dbl>     <dbl>\n 1  2001 Kate… tt00354… PG-13            118 Come…  6.40        44\n 2  2000 Chic… tt01206… G                 84 Anim…  7           88\n 3  2005 Fant… tt01206… PG-13            106 Acti…  5.70        40\n 4  2002 Frida tt01206… R                123 Biog…  7.40        61\n 5  2001 The … tt01207… PG-13            178 Adve…  8.80        92\n 6  2000 Miss… tt01207… PG-13            123 Acti…  6.10        59\n 7  2002 Resi… tt01208… R                100 Acti…  6.70        33\n 8  2000 X-Men tt01209… PG-13            104 Acti…  7.40        64\n 9  2000 The … tt01209… G                 78 Anim…  7.30        70\n10  2005 Corp… tt01211… PG                77 Anim…  7.40        83\n# … with 1,225 more rows, and 2 more variables: synopsis <chr>,\n#   votes <dbl>\n\nWriting Vectorized If/Else Statements\nMy last post covered one way to write if/else statements. In this lesson, however, I learned that there is a vectorized solution for this. I could use the if/else() function, which is part of the dplyr package, for applying if/else statements. The if/else function could replace the for-loops I wrote in the previous post. This function requires the following:\nA Vector/Multiple Vectors\nA Condition\nAn action to perform if condition is true\nAn action to perform if condition is false\nLet’s look at an example. I want to see if the movies in my data frame recieved more Golden Globe nominations than Oscar nominations. If a movie recieved more Golden Globe nominations, then the statement “more popular at the Golden Globes” would print. If a movie recieved more Oscar nominations, then the statement, “more popular at the Oscars” would print.\n\n\nawards_popular <- if_else(oscars_2018$Golden_Globes_nominated > oscars_2018$Oscar_nominated, \"more popular at the Golden Globes\", \"more Popular at the Oscars\")\n\nprint(as_tibble(awards_popular))\n\n\n# A tibble: 1,235 x 1\n   value                            \n   <chr>                            \n 1 more popular at the Golden Globes\n 2 more popular at the Golden Globes\n 3 more Popular at the Oscars       \n 4 more Popular at the Oscars       \n 5 more Popular at the Oscars       \n 6 more Popular at the Oscars       \n 7 more Popular at the Oscars       \n 8 more Popular at the Oscars       \n 9 more Popular at the Oscars       \n10 more Popular at the Oscars       \n# … with 1,225 more rows\n\nNested if_else() Functions\nSimilar to nested if/else statements, I can take a vectorized approach by nesting if_else() functions. When nesting these functions, I would specify a different if_else function to perform an action if the first condition is not met. In the below screenshot, I have three different if_else() functions representing three different conditions:\nIf number of Golden Globes nominations are greater than number of Oscar nominations then print “more popular at the Golden Globes”\nIf number of Golden Globes nominations are less number of than Oscar nominations then print “more popular at the Oscars”\nIf number of Golden Globes nominations are equal to number of Oscar nominations then print “both the Golden Globes and Oscars love you”\nFor each if_else() function in this chain, if the condition is not met, the R interpreter moves on to the next if_else function.\n\n\nawards_popular_result <- if_else(oscars_2018$Golden_Globes_nominated > oscars_2018$Oscar_nominated, \"more popular at the Golden Globes\",\n                                 if_else(oscars_2018$Golden_Globes_nominated < oscars_2018$Oscar_nominated, \"more popular at the Oscars\",\n                                         if_else(oscars_2018$Golden_Globes_nominated == oscars_2018$Oscar_nominated, \"both the Golden Globes and Oscars love you\", \"\")))\n\nprint(as_tibble(awards_popular_result))\n\n\n# A tibble: 1,235 x 1\n   value                                     \n   <chr>                                     \n 1 more popular at the Golden Globes         \n 2 more popular at the Golden Globes         \n 3 both the Golden Globes and Oscars love you\n 4 more popular at the Oscars                \n 5 more popular at the Oscars                \n 6 both the Golden Globes and Oscars love you\n 7 both the Golden Globes and Oscars love you\n 8 both the Golden Globes and Oscars love you\n 9 both the Golden Globes and Oscars love you\n10 more popular at the Oscars                \n# … with 1,225 more rows\n\nEach if_else function requires that I specify two action to take place based on whether or not the condition is true or false. However because I only have three cases here, I used a pair of empty quotes as the second action in the last if_else() function.\nGrouping and Summarizing Data Frames\nOne huge takeaway from this lesson is learning how to solve what are known as “split-apply-combine” problems in R. With a split-apply-combine problem, the data is split into groups, a function is performed on each group, and the results are summarized. According to DataQuest, this is useful for solving many data analysis problems that require the calculation of summary statistics. Let’s start by discussing how to group data.\nTwo functions that are useful for working on split-apply-combine problems are the group_by() function and the summarize() function. Both functions are part of the dplyr package. The group_by() function allows me to group data by variable. The summarize() function lets me apply a function like sum() or n() to each group. The n() function counts the number of data frame rows in each group.\nLet’s look at this example. I want to group my oscars_2018 data frame based on the genre variable. This is what the code looks like. As you recall from a previous post, the pipe operator(%>%) is used to chain functions together. This code splits rows of my oscars_2018 data frame into groups based on genre. I then saved this to the genre_wins data frame.\n\n\ngenre_wins <- oscars_2018 %>% group_by(genre)\ngenre_wins[1:10]\n\n\n# A tibble: 1,235 x 10\n# Groups:   genre [228]\n    year movie movie_id certificate duration genre  rate metascore\n   <dbl> <chr> <chr>    <chr>          <dbl> <chr> <dbl>     <dbl>\n 1  2001 Kate… tt00354… PG-13            118 Come…  6.40        44\n 2  2000 Chic… tt01206… G                 84 Anim…  7           88\n 3  2005 Fant… tt01206… PG-13            106 Acti…  5.70        40\n 4  2002 Frida tt01206… R                123 Biog…  7.40        61\n 5  2001 The … tt01207… PG-13            178 Adve…  8.80        92\n 6  2000 Miss… tt01207… PG-13            123 Acti…  6.10        59\n 7  2002 Resi… tt01208… R                100 Acti…  6.70        33\n 8  2000 X-Men tt01209… PG-13            104 Acti…  7.40        64\n 9  2000 The … tt01209… G                 78 Anim…  7.30        70\n10  2005 Corp… tt01211… PG                77 Anim…  7.40        83\n# … with 1,225 more rows, and 2 more variables: synopsis <chr>,\n#   votes <dbl>\n\nWhen I print the first few rows of my new genre_wins data frame, I can see the grouping variable and the number of groups specified. The grouping variable is genre and there are 228 genre groups.\nOnce the data frame is grouped, I can perform operations on each group using the summarize() function.\nTake a look at the example below. Let’s say I wanted to calculate how many awards were won in each genre. Once again, I grouped my data frame by genre and then used the summarize() function to add up the awards won in each genre. This was saved into a data frame I call genre_wins_one. When I print this data frame, I end up with the following:\n\n\ngenre_wins_one <- oscars_2018 %>% group_by(genre) %>% summarize(sum(awards_wins))\ngenre_wins_one\n\n\n# A tibble: 228 x 2\n   genre                      `sum(awards_wins)`\n   <chr>                                   <dbl>\n 1 Action|Adventure                            5\n 2 Action|Adventure|Biography                  0\n 3 Action|Adventure|Comedy                     6\n 4 Action|Adventure|Crime                      2\n 5 Action|Adventure|Drama                     48\n 6 Action|Adventure|Family                     3\n 7 Action|Adventure|Fantasy                   73\n 8 Action|Adventure|History                    5\n 9 Action|Adventure|Horror                     0\n10 Action|Adventure|Mystery                    3\n# … with 218 more rows\n\nI can see that the Action|Adventure|Fantasy genre has won 73 awards.\nMultiple Grouping and Summarizing\nI can also group my data frame by multiple variables like the screenshot below. I can see that my data frame is grouped by the genre and certificate variables. I then use the summarize() function to apply the n() function. As I mentioned earlier in the post, the n() function counts counts the number of data frame rows in each group.\n\n\noscars_2018 %>% group_by(genre,certificate) %>% summarize(total = n())\n\n\n# A tibble: 360 x 3\n# Groups:   genre [228]\n   genre                      certificate total\n   <chr>                      <chr>       <int>\n 1 Action|Adventure           PG-13           8\n 2 Action|Adventure|Biography PG-13           1\n 3 Action|Adventure|Biography R               1\n 4 Action|Adventure|Comedy    PG              3\n 5 Action|Adventure|Comedy    PG-13           7\n 6 Action|Adventure|Comedy    R               2\n 7 Action|Adventure|Crime     PG-13           5\n 8 Action|Adventure|Drama     PG-13          14\n 9 Action|Adventure|Drama     R               4\n10 Action|Adventure|Family    PG              3\n# … with 350 more rows\n\nJust as I grouped my data frame by multiple variables, I can specify multiple operations using the summarize() function.\nLet’s say I want to know the minimum, maximum and average Metacritic (stored in the metascore variable) score for each genre. I would first group my data frame by genre. I then use the summarize() function to apply the following functions: min(), max() and mean() to the metascore variable.\n\n\noscars_2018 %>%\n  group_by(genre) %>%\n  summarize(min = min(metascore),\n            max = max(metascore),\n            avg = mean(metascore))\n\n\n# A tibble: 228 x 4\n   genre                        min   max   avg\n   <chr>                      <dbl> <dbl> <dbl>\n 1 Action|Adventure              35    83  61.4\n 2 Action|Adventure|Biography    39    47  43  \n 3 Action|Adventure|Comedy       29    67  50.8\n 4 Action|Adventure|Crime        37    57  46.2\n 5 Action|Adventure|Drama        46    89  65.2\n 6 Action|Adventure|Family       20    56  38.8\n 7 Action|Adventure|Fantasy      30    93  55.5\n 8 Action|Adventure|History      85    85  85  \n 9 Action|Adventure|Horror       37    63  50  \n10 Action|Adventure|Mystery      43    76  58.5\n# … with 218 more rows\n\nWhen I’m done with a grouped data frame, it’s best to return it to its previous state by ungrouping it like so:\n\n\noscars_2018 %>% ungroup()\n\n\n\nThe Pipe Operator\nI mentioned earlier that the pipe operator(%>%) is used to chain functions together. It makes code easier to read and write but how does it work? DataQuest explains it this way:\n\nThe pipe originated with a package called maggritR. The tidyverse has adopted\nthe pipe as a key feature of its packages, so loading tidyverse packages loads\n%>% automatically. The pipe operator allows you to write code so that the\noutput of a function is passed to the next function from left to right. Most R > functions do a lot of computing work for you behind the scenes, and you as a\nuser interact with a “wrapper”. The pipe is a good example of this.\n\nI think this is best demonstrated with an example. Let’s say I wanted to add up the total number of reviews for the movie, The Lord of the Rings: The Fellowship of the Ring. I would first filter the data to retain information about the movie. Then, I would add a new column called total_reviews, containing the total number of reviews (adding user_reviews + critics_reviews variables). I store this in a data frame called lord_rings_reviews.\n\n\nlord_rings_reviews <- oscars_2018 %>% \n     filter(movie == \"The Lord of the Rings: The Fellowship of the Ring\") %>%\n     mutate(total_reviews = user_reviews + critic_reviews)\n\n\n\nWhen I type View(lord_rings_reviews), a file opens up containing all the data on this Lord of the Rings movie. The column total_reviews has been added in as the last column in the data frame.\n\n\n\nWhew, that just about covers it for vectorized functions. Until next time…\n\n\n\n",
    "preview": "posts/2020-02-10-vectorized-functions/total_reviews.jpg",
    "last_modified": "2020-10-15T01:03:16-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-02-06-control-structures/",
    "title": "Control Structures",
    "description": "Working with control structures in R.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-02-06",
    "categories": [
      "data science",
      "programming",
      "R",
      "control structures"
    ],
    "contents": "\n\n    pre code {\n      white-space: pre-wrap;\n    }\nThis past weekend was the Super Bowl. I thought for this post I would use a data set that was posted on Kaggle that contains data on the Super Bowl games from 1967 to present. This data set was put together by Timo Bozsolik.\nIn this post, I’m going to get into control structures. DataQuest says that control structures are necessary for repeated application or to execute an action only if a condition is met. Otherwise, writing code would be very tedious and not as fun.\nI admit I struggled with control structures in other languages. However with R, I finally feel like I have a grasp on this concept. I feel like something clicked in this lesson. So without further delay, let’s get into it!\nI’ll first load the tidyverse and janitor packages. I learned about the janitor package about a few days ago. It has simple functions for examining and cleaning data. This package came in handy for cleaning up the names of the columns in this dataset.\nAfter installing and loading the janitor package, I imported the data. Next, I created a new object called clean_superbowl, that has the clean names. The last line of code gives you a side by side comparison of the column names of the imported data and the cleaned data frame. You can find more information about the janitor package here.\n\n\nlibrary(tidyverse)\nlibrary(janitor)\nsuperbowl <-read_csv('/Users/User/datascidani2/_posts/2020-02-06-control-structures/superbowl.csv')\nclean_superbowl <-janitor::clean_names(superbowl)\ndata.frame(superbowl = colnames(superbowl), clean_superbowl = colnames(clean_superbowl))\n\n\n    superbowl clean_superbowl\n1        Date            date\n2          SB              sb\n3      Winner          winner\n4  Winner Pts      winner_pts\n5       Loser           loser\n6   Loser Pts       loser_pts\n7         MVP             mvp\n8     Stadium         stadium\n9        City            city\n10      State           state\n\nView(clean_superbowl)\n\n\n\nConditional Statements\nA conditional statement is a type of control structure that performs different calculations or actions based on whether or not a predefined condition is TRUE or FALSE. You can express conditional statements using comparison operators. One type of conditional statement is called an if statement. Let’s look at the screenshot below. I created a conditional statement that looks at the titles of the Super Bowl games. In this case, the condition is the first element of the Super Bowl title column being greater than 53. The action is the print statement, “Jennifer Lopez and Shakira performed at this Super Bowl.\n\n\nif (clean_superbowl$sb[1] > 53) {\n     print(\"JLo and Shakira performed at this Superbowl.\")\n}\n\n\n[1] \"JLo and Shakira performed at this Superbowl.\"\n\nI could add another type of conditional statement called the else statement. I can combine my if and else statements to form what is called an if/else statement. An action is executed if the condition in the if statement is TRUE. If that condition is not TRUE, the action in the else statement is executed.\n\n\nif (clean_superbowl$sb[1] <= 53) {\n     print(\"JLo and Shakira performed at this Superbowl.\")\n}else{\n     print(\"No performance from JLo and Shakira at this Superbowl.\")\n}\n\n\n[1] \"No performance from JLo and Shakira at this Superbowl.\"\n\nThere is also something called nested else/if statements where an else/if statement is written within another else/if statement like so…\n\n\nif(clean_superbowl$sb[1] > 53){\n    print(\"JLo and Shakira performed at this Superbowl.\")\n}else if(clean_superbowl$sb[1] < 53) {\n    print(\"No performance from JLo and Shakira at this Superbowl.\")\n}else if (clean_superbowl$sb[1] == 53){\n      print(\"Maroon 5 played at the 2019 Superbowl.\")\n}\n\n\n[1] \"JLo and Shakira performed at this Superbowl.\"\n\nThe problem with conditional statements is that they are inefficient. They are lengthy and if you have a situation where you have multiple conditional statements, it becomes repetitive. Another type of control structure solves the problem of repetition: For-loops.\nFor-loops\nPrint Elements of A Sequence\nFor-loops perform an operation a given number of times, allowing me to execute a piece of code repeatedly on elements of a sequence. For example, let’s say I want to print all the Super Bowl titles. I could write a for-loop that looks like this:\n\n\nfor(i in clean_superbowl$sb) {\n       print(i)\n}\n\n\n[1] \"LIV (54)\"\n[1] \"LIII (53)\"\n[1] \"LII (52)\"\n[1] \"LI (51)\"\n[1] \"50\"\n[1] \"XLIX (49)\"\n[1] \"XLVIII (48)\"\n[1] \"XLVII (47)\"\n[1] \"XLVI (46)\"\n[1] \"XLV (45)\"\n[1] \"XLIV (44)\"\n[1] \"XLIII (43)\"\n[1] \"XLII (42)\"\n[1] \"XLI (41)\"\n[1] \"XL (40)\"\n[1] \"XXXIX (39)\"\n[1] \"XXXVIII (38)\"\n[1] \"XXXVII (37)\"\n[1] \"XXXVI (36)\"\n[1] \"XXXV (35)\"\n[1] \"XXXIV (34)\"\n[1] \"XXXIII (33)\"\n[1] \"XXXII (32)\"\n[1] \"XXXI (31)\"\n[1] \"XXX (30)\"\n[1] \"XXIX (29)\"\n[1] \"XXVIII (28)\"\n[1] \"XXVII (27)\"\n[1] \"XXVI (26)\"\n[1] \"XXV (25)\"\n[1] \"XXIV (24)\"\n[1] \"XXIII (23)\"\n[1] \"XXII (22)\"\n[1] \"XXI (21)\"\n[1] \"XX (20)\"\n[1] \"XIX (19)\"\n[1] \"XVIII (18)\"\n[1] \"XVII (17)\"\n[1] \"XVI (16)\"\n[1] \"XV (15)\"\n[1] \"XIV (14)\"\n[1] \"XIII (13)\"\n[1] \"XII (12)\"\n[1] \"XI (11)\"\n[1] \"X (10)\"\n[1] \"IX (9)\"\n[1] \"VIII (8)\"\n[1] \"VII (7)\"\n[1] \"VI (6)\"\n[1] \"V (5)\"\n[1] \"IV (4)\"\n[1] \"III (3)\"\n[1] \"II (2)\"\n[1] \"I (1)\"\n\nLet’s examine this for-loop. The index variable i represents the element of a sequence. I can read this as “for every element in the sb column of the clean_superbowl data frame, print the element.” Although not shown here, this for-loop printed every single Super Bowl title until it reached the end of all the titles(in this case Super Bowl I (1)).\nI don’t always have to use i. I could use any variable name. The variable name should describe what the variable represents making code more readable. I also would avoid using common names as variables. For example, I would not use sum as a variable name because it can cause problems if I wanted to use the sum() function later on.\nLooping Over Rows in a Data Frame\nWhen writing a for-loop, the elements I specify can be values, vectors, or data structures. In this next example, I wrote a for-loop to execute an operation on elements that are rows in a data frame. This for-loop calculates how many points the winning team won by for each game.\n\n\nfor (i in 1:nrow(clean_superbowl)) {\n  print(clean_superbowl$winner_pts[i] - clean_superbowl$loser_pts[i])\n}\n\n\n[1] 11\n[1] 10\n[1] 8\n[1] 6\n[1] 14\n[1] 4\n[1] 35\n[1] 3\n[1] 4\n[1] 6\n[1] 14\n[1] 4\n[1] 3\n[1] 12\n[1] 11\n[1] 3\n[1] 3\n[1] 27\n[1] 3\n[1] 27\n[1] 7\n[1] 15\n[1] 7\n[1] 14\n[1] 10\n[1] 23\n[1] 17\n[1] 35\n[1] 13\n[1] 1\n[1] 45\n[1] 4\n[1] 32\n[1] 19\n[1] 36\n[1] 22\n[1] 29\n[1] 10\n[1] 5\n[1] 17\n[1] 12\n[1] 4\n[1] 17\n[1] 18\n[1] 4\n[1] 10\n[1] 17\n[1] 7\n[1] 21\n[1] 3\n[1] 16\n[1] 9\n[1] 19\n[1] 25\n\nLet’s break this down further. I’ll start by explaining the first line of code. In the clean_superbowl data frame, each match has its own row. Since I want to perform the subtraction operation for each row of the data frame, the first part of the for-loop will consist of defining i as an element of the sequence of numbers from one to fifty-four (the number of rows in the data frame).\nThe nrow(clean_superbowl) returns the number of rows in the data frame. The print() function is used to display the results.\nNested Control Structures\nAs I mentioned previously, executing one or more control structures inside another is called nesting. A for-loop can be used to loop over conditional statements. In this example, I used a for-loop, that for each row in the clean_superbowl data frame, print “Aww it was so close!” if the difference between the winner points and loser points is less than 10 and ” A Total Blowout!” if not.\n\n\nfor(i in 1:nrow(clean_superbowl)) {\n  if (clean_superbowl$winner_pts[i]-clean_superbowl$loser_pts[i] < 10) {\n    print(\"Aww it was so close!\")\n  } else { \n    print(\"A Total Blowout!\")\n  }\n}\n\n\n[1] \"A Total Blowout!\"\n[1] \"A Total Blowout!\"\n[1] \"Aww it was so close!\"\n[1] \"Aww it was so close!\"\n[1] \"A Total Blowout!\"\n[1] \"Aww it was so close!\"\n[1] \"A Total Blowout!\"\n[1] \"Aww it was so close!\"\n[1] \"Aww it was so close!\"\n[1] \"Aww it was so close!\"\n[1] \"A Total Blowout!\"\n[1] \"Aww it was so close!\"\n[1] \"Aww it was so close!\"\n[1] \"A Total Blowout!\"\n[1] \"A Total Blowout!\"\n[1] \"Aww it was so close!\"\n[1] \"Aww it was so close!\"\n[1] \"A Total Blowout!\"\n[1] \"Aww it was so close!\"\n[1] \"A Total Blowout!\"\n[1] \"Aww it was so close!\"\n[1] \"A Total Blowout!\"\n[1] \"Aww it was so close!\"\n[1] \"A Total Blowout!\"\n[1] \"A Total Blowout!\"\n[1] \"A Total Blowout!\"\n[1] \"A Total Blowout!\"\n[1] \"A Total Blowout!\"\n[1] \"A Total Blowout!\"\n[1] \"Aww it was so close!\"\n[1] \"A Total Blowout!\"\n[1] \"Aww it was so close!\"\n[1] \"A Total Blowout!\"\n[1] \"A Total Blowout!\"\n[1] \"A Total Blowout!\"\n[1] \"A Total Blowout!\"\n[1] \"A Total Blowout!\"\n[1] \"A Total Blowout!\"\n[1] \"Aww it was so close!\"\n[1] \"A Total Blowout!\"\n[1] \"A Total Blowout!\"\n[1] \"Aww it was so close!\"\n[1] \"A Total Blowout!\"\n[1] \"A Total Blowout!\"\n[1] \"Aww it was so close!\"\n[1] \"A Total Blowout!\"\n[1] \"A Total Blowout!\"\n[1] \"Aww it was so close!\"\n[1] \"A Total Blowout!\"\n[1] \"Aww it was so close!\"\n[1] \"A Total Blowout!\"\n[1] \"Aww it was so close!\"\n[1] \"A Total Blowout!\"\n[1] \"A Total Blowout!\"\n\nStoring For-Loop Output in Objects\nThough I can print out the output of my for-loop, I ultimately want to store the output of my for-loop in an object so that I can use it. In this next example, I wanted to calculate the total number of points scored in each Super Bowl game. I first created an empty vector, total_points_scored. I then wrote the for-loop to add new elements into the vector. The new elements are the sums of winner_pts and loser_pts for each game.\n\n\ntotal_points_scored <-c()\nfor(i in 1:nrow(clean_superbowl)) {\n    total_points_scored <-c(total_points_scored, clean_superbowl$winner_pts[i]+ clean_superbowl$loser_pts[i])\n}\n\ntotal_points_scored\n\n\n [1] 51 16 74 62 34 52 51 65 38 56 48 50 31 46 31 45 61 69 37 41 39 53\n[23] 55 56 44 75 43 69 61 39 65 36 52 59 56 54 47 44 47 37 50 66 37 46\n[45] 38 22 31 21 27 29 30 23 47 45\n\nAfter running the for-loop, the total_points_scored vector contains a sum winner_pts and loser_pts for each game.\nMore Than Two Cases\nThere are times where my code would need to specify more than two outcomes. This is where selection control statements come in. Selection control statements allow me to specify more than two outcomes by adding else if statements to my code. Let’s say if I wanted to specify three conditions: games that were won by less than or equal to 10 points, games that were won by greater than or equal to 11 points and less than or equal to 20 points, games that were won by greater than 21 points. I can write the following:\n\n\nsuperbowl_won_by <-c()\n\nfor(i in 1:nrow(clean_superbowl)) {\n  if(clean_superbowl$winner_pts[i]-clean_superbowl$loser_pts[i] < 10) {\n    superbowl_won_by <- c(superbowl_won_by, \"A Close Game!\")\n  }else if (clean_superbowl$winner_pts[i]-clean_superbowl$loser_pts[i] >= 11 & clean_superbowl$winner_pts[i]-clean_superbowl$loser_pts[i] <= 20){\n    superbowl_won_by <- c(superbowl_won_by, \"A Total Blowout!\")\n  } else if (clean_superbowl$winner_pts[i]-clean_superbowl$loser_pts[i] > 21){\n    superbowl_won_by <- c(superbowl_won_by, \"Go back to the drawing board!\")\n  }\n}\n\nsuperbowl_won_by[1:20]\n\n\n [1] \"A Total Blowout!\"              \"A Close Game!\"                \n [3] \"A Close Game!\"                 \"A Total Blowout!\"             \n [5] \"A Close Game!\"                 \"Go back to the drawing board!\"\n [7] \"A Close Game!\"                 \"A Close Game!\"                \n [9] \"A Close Game!\"                 \"A Total Blowout!\"             \n[11] \"A Close Game!\"                 \"A Close Game!\"                \n[13] \"A Total Blowout!\"              \"A Total Blowout!\"             \n[15] \"A Close Game!\"                 \"A Close Game!\"                \n[17] \"Go back to the drawing board!\" \"A Close Game!\"                \n[19] \"Go back to the drawing board!\" \"A Close Game!\"                \n\nAs you can see, each row printed a statement based on the condition I specified.\nOkay, that’s all for this post. I’m signing off for now! Until next time…\n\n\n\n",
    "preview": {},
    "last_modified": "2020-10-13T20:15:13-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2020-02-03-installing-rstudio/",
    "title": "Installing RStudio",
    "description": "Installing R Studio.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-02-03",
    "categories": [
      "data science",
      "programming",
      "R",
      "R Studio"
    ],
    "contents": "\nIn honor of the RStudio Conference that took place in San Francisco last week, I wanted to talk a bit about RStudio, the IDE that I’m using to practice R. This is also a lesson in the Data Analyst in R track called, Guided Project: Install RStudio.\nI had a bit of a struggle installing R and R Studio. Initially, I had Anaconda installed. Anaconda is a Python package manager that comes preinstalled with a lot of Python libraries that are useful for data science. It also comes with some preinstalled applications, one of which is R Studio. I first installed R using this website, next I installed Anaconda, then I installed RStudio. I tried to use RStudio in this way and it did not work for me. I tried typing different expressions into the RStudio console and it did not work. I kept installing and reinstalling R and Anaconda to no avail.\nOne day, I decided to uninstall R, Anaconda, R Studio. I decided that instead of trying to install R Studio through Anaconda, I would install RStudio directly through its website. Besides, I did not see the point of reinstalling Anaconda to only use one app. I first went to the R website and downloaded R. I followed the instructions and tested R in the R console to make sure it worked. I then went to the RStudio website and downloaded RStudio. I opened R Studio and tried to type expressions in the R Studio and low and behold it worked!\nNow that I have RStudio working and been using it for a few weeks, I wanted to share some of my favorite features so far.\nR Studio InterfaceFirst off, I really enjoy the workspace being divided into four quadrants. It allows me to see everything at once. If I wanted to minimize one of the quadrants, I could do that too. It looks to be very flexible in that regard.\nAnother feature I like is being able to import a data set. In my previous post, I touched on one way to import a data set. Another way be would be to go to the Environment tab and click on Import Dataset. I used the readr option because it uses functions that I’ve been taught in this Data Analyst track.\nThe Environment tab shows you objects that have been stored in your global environment. I could always delete these objects if there are too many and they begin to cause confusion.\nThe last feature I wanted to talk about is the History tab which is a saved record of every single command that I typed into the console. I really like this feature because it saves me from retyping the same commands. Even if I exit out of RStudio, the history is still there.\nThis is just the beginning of my use of RStudio. I have yet to use RStudio to its full potential. I’m already excited about using the plots tab and connecting with databases. I can’t wait to use it more and discover more features.\nThis lesson marks the end of the Intro to Programming in R course in the Data Analyst in R track. I’m moving on to Intermediate R Programming! Until next time…\n\n\n\n",
    "preview": {},
    "last_modified": "2020-10-15T01:00:40-04:00",
    "input_file": {}
  },
  {
    "path": "posts/working_with_dataframes 01-30-20/",
    "title": "Working With Data Frames",
    "description": "Working with data frames in R.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-01-30",
    "categories": [
      "data science",
      "data types",
      "programming",
      "R",
      "data frames"
    ],
    "contents": "\n\n    pre code {\n      white-space: pre-wrap;\n    }\nBasketball has been heavy on mind lately. One reason being the All the Smoke podcast that I listen to with Matt Barnes and Stephen Jackson every week. I’ve been listening to the podcast since day one. Another reason has been the recent passing of Kobe Bryant, his daughter Gianna and the seven other lives that were taken in that helicopter accident. When I think of Kobe, I think about my brother and the kids I went to school with. They would shout ‘KOBE’ anytime they threw something.\nBecause of people like my brother, like those kids I went to school with, I decided to go with a basketball theme with this post. I wanted to shed light on some of the players that Kobe inspired and some that maybe inspired him. The data set that I will use for this blog post was posted on Kaggle by Jason Baruch. Baruch created the NBA Player of the Week data set that analyzes player of the week data from 1979-80 season to the present. I decided to download the csv and play around a bit. With that said, let’s get into data frames in R.\nData frames are a list of vectors of equal length. They can contain multiple data types and they are probably the most common data structure in R. Not only did I learn about data frames but I learned about some R packages that makes doing data science with data frames efficient.\nInstalling and Loading Packages\nThe first thing I did as part of the DataQuest lesson was to install the readr package, which is part of the tidyverse. Readr is designed to improve data science workflow. DataQuest gives me a few ways that readr does this:\nSpeed: Importing larger data files with readr functions is generally faster than using base R functions. By the way, base R is just the basic software that comes with the R programming language.\nCode reproducibility: While base R function behavior depends in part on your operating system and environment variables, this is not the case for readr. When you use readr to import files, code that works on your computer will work on someone else’s.\nConsistency: The readr package shares a common syntax and design philosophy with other tidyverse packages that we’ll introduce in upcoming courses.\nAfter installing readr, I loaded the package using the library function.\n\n\n\nImporting Data with R\nRStudio (the IDE I’ve been using in my posts) has an option to import data. To do this I went to File -> Import Dataset -> From Text(readr). This leads to a screen that prompts me type a file name or URL. However, I decided to click on Browse which leads me to import a document. When I imported my csv that I downloaded from Kaggle, this is what I get:\n\n\n\nAfter I click import, my csv file is opened like this.\n\n\n\nNote: The tidyverse is a collection of packages designed to make using R for data science more effective. In addition to readr, tidyverse includes dplyr which will be discussed later. Instead of installing each package, I installed tidyverse just as I did with readr example in the above screenshots.\n\n\nlibrary(tidyverse)\n\nNBA_player_of_the_week <- read_csv('/Users/User/datascidani2/_posts/working_with_dataframes 01-30-20/NBA_player_of_the_week.csv')\n\n\n\n\n\nView(NBA_player_of_the_week)\n\n\n\nTibbles\nTo make the data easier to work with, I decided to get my data frame into a tibble. A tibble is the same as a data frame in base R. DataQuest mentions that they are two-dimensional data structures that store data of multiple types. They also have very important advantages: clarity, consistency and printing. You can type the name of a tibble and R will only print the first 10 rows.\n\n\ntibble::as_tibble(NBA_player_of_the_week)\n\n\n# A tibble: 1,334 x 17\n   Player Team  Conference Date  Position Height Weight   Age\n   <chr>  <chr> <chr>      <chr> <chr>    <chr>   <dbl> <dbl>\n 1 Ben S… Phil… East       20-J… PF       6'10      230    23\n 2 Kawhi… Los … West       20-J… F        6'7       230    28\n 3 Josh … Phil… East       13-J… G        6'6       200    26\n 4 DeMar… San … West       13-J… GF       6'7       220    30\n 5 Giann… Milw… East       6-Ja… F        6'11      242    25\n 6 LeBro… Los … West       6-Ja… F        6'8       250    35\n 7 Jayle… Bost… East       30-D… SF       6'7       220    23\n 8 Brand… New … West       30-D… SF       6'9       190    22\n 9 Kyle … Toro… East       23-D… PG       6'1       196    33\n10 Denni… Okla… West       23-D… PG       6'1       172    26\n# … with 1,324 more rows, and 9 more variables: Draft_Year <dbl>,\n#   Seasons_in_league <dbl>, Season <chr>, Season_short <dbl>,\n#   Pre_draft_Team <chr>, Real_value <dbl>, Height_CM <dbl>,\n#   Weight_KG <dbl>, Last_Season <dbl>\n\nIndexing Data Frames\nFor data frames, I can use indexing to return a specific, row, column or value. It’s pretty similar to indexing matrices. If I wanted to index the column “Team”, I could do this in a couple of ways:\nBy position :\n\n\nNBA_player_of_the_week[, 2]\n\n\n# A tibble: 1,334 x 1\n   Team                 \n   <chr>                \n 1 Philadelphia Sixers  \n 2 Los Angeles Clippers \n 3 Philadelphia Sixers  \n 4 San Antonio Spurs    \n 5 Milwaukee Bucks      \n 6 Los Angeles Lakers   \n 7 Boston Celtics       \n 8 New Orleans Pelicans \n 9 Toronto Raptors      \n10 Oklahoma City Thunder\n# … with 1,324 more rows\n\nBy column name:\n\n\nNBA_player_of_the_week[, \"Team\"]\n\n\n# A tibble: 1,334 x 1\n   Team                 \n   <chr>                \n 1 Philadelphia Sixers  \n 2 Los Angeles Clippers \n 3 Philadelphia Sixers  \n 4 San Antonio Spurs    \n 5 Milwaukee Bucks      \n 6 Los Angeles Lakers   \n 7 Boston Celtics       \n 8 New Orleans Pelicans \n 9 Toronto Raptors      \n10 Oklahoma City Thunder\n# … with 1,324 more rows\n\nDataQuest also mentioned that I could use a $ symbol to specify a column though when I tried this method R printed 1000 rows of data.\n\n\n\nHere are some more examples of indexing data frames:\n\n\nNBA_player_of_the_week$Team[2]\n\n\n[1] \"Los Angeles Clippers\"\n\n\n\nNBA_player_of_the_week[6,2]\n\n\n# A tibble: 1 x 1\n  Team              \n  <chr>             \n1 Los Angeles Lakers\n\n\n\nNBA_player_of_the_week[6, ]\n\n\n# A tibble: 1 x 17\n  Player Team  Conference Date  Position Height Weight   Age\n  <chr>  <chr> <chr>      <chr> <chr>    <chr>   <dbl> <dbl>\n1 LeBro… Los … West       6-Ja… F        6'8       250    35\n# … with 9 more variables: Draft_Year <dbl>, Seasons_in_league <dbl>,\n#   Season <chr>, Season_short <dbl>, Pre_draft_Team <chr>,\n#   Real_value <dbl>, Height_CM <dbl>, Weight_KG <dbl>,\n#   Last_Season <dbl>\n\n\n\nNBA_player_of_the_week[c(2:8), c(\"Player\", \"Pre_draft_Team\")]\n\n\n# A tibble: 7 x 2\n  Player                Pre_draft_Team                         \n  <chr>                 <chr>                                  \n1 Kawhi Leonard         San Diego State                        \n2 Josh Richardson       Tennessee                              \n3 DeMar DeRozan         USC                                    \n4 Giannis Antetokounmpo Filathlitikos Div II Greece (Greece)   \n5 LeBron James          St. Vincent St. Mary High School (Ohio)\n6 Jaylen Brown          California                             \n7 Brandon Ingram        Duke                                   \n\nWorking With Data Frame Columns\nI could simplify my data frame to contain only variables(the column names) that are relevant for my data analysis.\nFor example, I want to create a new data frame that includes the names of the players, their teams, characteristics(height, weight, age), draft year and how many seasons they’ve played in the league. I would use dplyr, a tidyverse package designed for analyzing data in data frames.\nTo use this package, I would install and load it just as I did with the readr package. The dplyr function select() allows me to create a new data frame with only the columns containing the variables I want to use for my analysis. I realized that I already have tidyverse installed so I loaded that before creating this new data frame.\n\n\nNBA_player_of_the_week_select <- NBA_player_of_the_week %>% select(Player, Team, Position, Height, Weight, Age, Draft_Year, Seasons_in_league)\n\nNBA_player_of_the_week_select\n\n\n# A tibble: 1,334 x 8\n   Player Team  Position Height Weight   Age Draft_Year\n   <chr>  <chr> <chr>    <chr>   <dbl> <dbl>      <dbl>\n 1 Ben S… Phil… PF       6'10      230    23       2016\n 2 Kawhi… Los … F        6'7       230    28       2011\n 3 Josh … Phil… G        6'6       200    26       2015\n 4 DeMar… San … GF       6'7       220    30       2009\n 5 Giann… Milw… F        6'11      242    25       2013\n 6 LeBro… Los … F        6'8       250    35       2003\n 7 Jayle… Bost… SF       6'7       220    23       2016\n 8 Brand… New … SF       6'9       190    22       2016\n 9 Kyle … Toro… PG       6'1       196    33       2006\n10 Denni… Okla… PG       6'1       172    26       2013\n# … with 1,324 more rows, and 1 more variable:\n#   Seasons_in_league <dbl>\n\nI could also create new variables and add them to my data frame as columns using another dplyr function called mutate().\n\n\nNBA_player_of_the_week_mutate <- NBA_player_of_the_week %>% mutate(Draft_Age = Age-(2020-Draft_Year))\n\nNBA_player_of_the_week_mutate\n\n\n# A tibble: 1,334 x 18\n   Player Team  Conference Date  Position Height Weight   Age\n   <chr>  <chr> <chr>      <chr> <chr>    <chr>   <dbl> <dbl>\n 1 Ben S… Phil… East       20-J… PF       6'10      230    23\n 2 Kawhi… Los … West       20-J… F        6'7       230    28\n 3 Josh … Phil… East       13-J… G        6'6       200    26\n 4 DeMar… San … West       13-J… GF       6'7       220    30\n 5 Giann… Milw… East       6-Ja… F        6'11      242    25\n 6 LeBro… Los … West       6-Ja… F        6'8       250    35\n 7 Jayle… Bost… East       30-D… SF       6'7       220    23\n 8 Brand… New … West       30-D… SF       6'9       190    22\n 9 Kyle … Toro… East       23-D… PG       6'1       196    33\n10 Denni… Okla… West       23-D… PG       6'1       172    26\n# … with 1,324 more rows, and 10 more variables: Draft_Year <dbl>,\n#   Seasons_in_league <dbl>, Season <chr>, Season_short <dbl>,\n#   Pre_draft_Team <chr>, Real_value <dbl>, Height_CM <dbl>,\n#   Weight_KG <dbl>, Last_Season <dbl>, Draft_Age <dbl>\n\nAs you can see, a new column called Draft_Age was added to my table.\n\n\n\nFiltering A Data Frame\nUsing the filter() function, I could filter a data frame either using a single condition or multiple conditions. This is where the comparison operators come in.\nSingle Conditions\nI could simplify my data frame further by filtering. I would use another dplyr function, filter() to specify conditions that variables must meet in order to be retained in my data frame.\nIf I want to retain data on players who play for the Eastern Conference, I would type this:\n\n\nNBA_player_of_the_week_east <- NBA_player_of_the_week %>% filter(Conference == \"East\")\n\nNBA_player_of_the_week_east\n\n\n# A tibble: 417 x 17\n   Player Team  Conference Date  Position Height Weight   Age\n   <chr>  <chr> <chr>      <chr> <chr>    <chr>   <dbl> <dbl>\n 1 Ben S… Phil… East       20-J… PF       6'10      230    23\n 2 Josh … Phil… East       13-J… G        6'6       200    26\n 3 Giann… Milw… East       6-Ja… F        6'11      242    25\n 4 Jayle… Bost… East       30-D… SF       6'7       220    23\n 5 Kyle … Toro… East       23-D… PG       6'1       196    33\n 6 Bam A… Miam… East       16-D… C        6'10      255    22\n 7 Jimmy… Miam… East       9-De… GF       6'8       232    30\n 8 Giann… Milw… East       2-De… F        6'11      242    25\n 9 Spenc… Broo… East       25-N… PG       6'6       210    26\n10 Nikol… Orla… East       18-N… PF       7'0       260    29\n# … with 407 more rows, and 9 more variables: Draft_Year <dbl>,\n#   Seasons_in_league <dbl>, Season <chr>, Season_short <dbl>,\n#   Pre_draft_Team <chr>, Real_value <dbl>, Height_CM <dbl>,\n#   Weight_KG <dbl>, Last_Season <dbl>\n\nLet’s say I wanted to retain data on players whose weight is greater than 200 pounds. I would write this:\n\n\nNBA_player_of_the_week_weight <- NBA_player_of_the_week %>% filter(Weight > 200)\n\nNBA_player_of_the_week_weight\n\n\n# A tibble: 1,004 x 17\n   Player Team  Conference Date  Position Height Weight   Age\n   <chr>  <chr> <chr>      <chr> <chr>    <chr>   <dbl> <dbl>\n 1 Ben S… Phil… East       20-J… PF       6'10      230    23\n 2 Kawhi… Los … West       20-J… F        6'7       230    28\n 3 DeMar… San … West       13-J… GF       6'7       220    30\n 4 Giann… Milw… East       6-Ja… F        6'11      242    25\n 5 LeBro… Los … West       6-Ja… F        6'8       250    35\n 6 Jayle… Bost… East       30-D… SF       6'7       220    23\n 7 Bam A… Miam… East       16-D… C        6'10      255    22\n 8 LeBro… Los … West       16-D… F        6'8       250    35\n 9 Jimmy… Miam… East       9-De… GF       6'8       232    30\n10 Antho… Los … West       9-De… PF       6'10      253    26\n# … with 994 more rows, and 9 more variables: Draft_Year <dbl>,\n#   Seasons_in_league <dbl>, Season <chr>, Season_short <dbl>,\n#   Pre_draft_Team <chr>, Real_value <dbl>, Height_CM <dbl>,\n#   Weight_KG <dbl>, Last_Season <dbl>\n\nMultiple Conditions\nI was introduced to two new operators: The & operator specifies that both criteria in an expression must be met. The | operator specifies that at least one of the criteria in the expression must be met.\n\n\nNBA_player_of_the_week_stature <- NBA_player_of_the_week %>% filter(Weight > 200 & Height > \"6'5\")\n\nNBA_player_of_the_week_stature\n\n\n# A tibble: 684 x 17\n   Player Team  Conference Date  Position Height Weight   Age\n   <chr>  <chr> <chr>      <chr> <chr>    <chr>   <dbl> <dbl>\n 1 Kawhi… Los … West       20-J… F        6'7       230    28\n 2 DeMar… San … West       13-J… GF       6'7       220    30\n 3 LeBro… Los … West       6-Ja… F        6'8       250    35\n 4 Jayle… Bost… East       30-D… SF       6'7       220    23\n 5 LeBro… Los … West       16-D… F        6'8       250    35\n 6 Jimmy… Miam… East       9-De… GF       6'8       232    30\n 7 Carme… Port… West       2-De… F        6'8       240    35\n 8 Spenc… Broo… East       25-N… PG       6'6       210    26\n 9 Luka … Dall… West       25-N… SF       6'7       218    21\n10 Nikol… Orla… East       18-N… PF       7'0       260    29\n# … with 674 more rows, and 9 more variables: Draft_Year <dbl>,\n#   Seasons_in_league <dbl>, Season <chr>, Season_short <dbl>,\n#   Pre_draft_Team <chr>, Real_value <dbl>, Height_CM <dbl>,\n#   Weight_KG <dbl>, Last_Season <dbl>\n\n\n\nNBA_player_of_the_week_draft <- NBA_player_of_the_week %>% filter(Draft_Year > 2014 | Seasons_in_league <= 5)\n\nNBA_player_of_the_week_draft\n\n\n# A tibble: 692 x 17\n   Player Team  Conference Date  Position Height Weight   Age\n   <chr>  <chr> <chr>      <chr> <chr>    <chr>   <dbl> <dbl>\n 1 Ben S… Phil… East       20-J… PF       6'10      230    23\n 2 Josh … Phil… East       13-J… G        6'6       200    26\n 3 Jayle… Bost… East       30-D… SF       6'7       220    23\n 4 Brand… New … West       30-D… SF       6'9       190    22\n 5 Bam A… Miam… East       16-D… C        6'10      255    22\n 6 Spenc… Broo… East       25-N… PG       6'6       210    26\n 7 Luka … Dall… West       25-N… SF       6'7       218    21\n 8 Pasca… Toro… East       11-N… F        6'9       230    25\n 9 Trae … Atla… East       28-O… PG       6'2       180    21\n10 Karl-… Minn… West       28-O… C        7'0       248    24\n# … with 682 more rows, and 9 more variables: Draft_Year <dbl>,\n#   Seasons_in_league <dbl>, Season <chr>, Season_short <dbl>,\n#   Pre_draft_Team <chr>, Real_value <dbl>, Height_CM <dbl>,\n#   Weight_KG <dbl>, Last_Season <dbl>\n\nArranging Data Frames by Variables\nAnother dplyr function, arrange() allows me to specify a variable I want to use to reorder rows of my data frame. Let’s say that I want to arrange my data so that the players’ draft year is in ascending order. I would type this:\n\n# A tibble: 1,334 x 17\n   Player Team  Conference Date  Position Height Weight   Age\n   <chr>  <chr> <chr>      <chr> <chr>    <chr>   <dbl> <dbl>\n 1 Rick … Hous… <NA>       10-F… F        6'7       205    35\n 2 Elvin… Wash… <NA>       9-No… FC       6'9       235    35\n 3 Karee… Los … <NA>       24-M… C        7'2       225    37\n 4 Karee… Los … <NA>       8-Ap… C        7'2       225    36\n 5 Karee… Los … <NA>       12-F… C        7'2       225    36\n 6 Karee… Los … <NA>       28-F… C        7'2       225    34\n 7 Karee… Los … <NA>       21-D… C        7'2       225    33\n 8 Karee… Los … <NA>       17-F… C        7'2       225    32\n 9 Karee… Los … <NA>       9-De… C        7'2       225    32\n10 Tiny … Bost… <NA>       11-J… PG       6'1       150    32\n# … with 1,324 more rows, and 9 more variables: Draft_Year <dbl>,\n#   Seasons_in_league <dbl>, Season <chr>, Season_short <dbl>,\n#   Pre_draft_Team <chr>, Real_value <dbl>, Height_CM <dbl>,\n#   Weight_KG <dbl>, Last_Season <dbl>\n\nLet’s say I change my mind and I want the players’ draft year to be in descending order. It would look like this:\n\n# A tibble: 1,334 x 17\n   Player Team  Conference Date  Position Height Weight   Age\n   <chr>  <chr> <chr>      <chr> <chr>    <chr>   <dbl> <dbl>\n 1 Luka … Dall… West       25-N… SF       6'7       218    21\n 2 Trae … Atla… East       28-O… PG       6'2       180    21\n 3 Trae … Atla… East       25-M… PG       6'2       180    20\n 4 Bam A… Miam… East       16-D… C        6'10      255    22\n 5 Donov… Utah… West       4-Ma… SG       6'3       215    22\n 6 Donov… Utah… West       14-J… SG       6'3       215    22\n 7 Ben S… Phil… East       20-J… PF       6'10      230    23\n 8 Jayle… Bost… East       30-D… SF       6'7       220    23\n 9 Brand… New … West       30-D… SF       6'9       190    22\n10 Pasca… Toro… East       11-N… F        6'9       230    25\n# … with 1,324 more rows, and 9 more variables: Draft_Year <dbl>,\n#   Seasons_in_league <dbl>, Season <chr>, Season_short <dbl>,\n#   Pre_draft_Team <chr>, Real_value <dbl>, Height_CM <dbl>,\n#   Weight_KG <dbl>, Last_Season <dbl>\n\nWhew, okay that was a lot! That’s it for data frames! Until next time…\n\n\n\n",
    "preview": "posts/working_with_dataframes 01-30-20/install_load_packages.jpg",
    "last_modified": "2020-10-15T00:54:10-04:00",
    "input_file": {}
  },
  {
    "path": "posts/working_with_lists 01-27-20/",
    "title": "Working With Lists",
    "description": "Working with lists in R.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-01-27",
    "categories": [
      "data science",
      "data types",
      "programming",
      "R",
      "lists"
    ],
    "contents": "\n\n    pre code {\n      white-space: pre-wrap;\n    }\nThe next topic I learned about in the DataQuest Data Analyst in R track is a list. I decided that in honor of music’s biggest night, also known the Grammys that took place last night, the examples in this post are going to be music focused. So without further ado, let’s get it started!\nDataQuest defines lists as specialized vectors that contain multiple types of objects. These objects can be different data structures including single data elements, vectors, and matrices. So why lists? Storing objects in lists allow me to make use of some of R’s features for performing the same operation on each object in the list. The list is created using the list() function, like so:\n\n\nmusic_genres <- list(\"jazz\", \"reggae\", \"pop\", \"hip hop\", \"R&B\", \"rock\", \"country\")\nmusic_genres\n\n\n[[1]]\n[1] \"jazz\"\n\n[[2]]\n[1] \"reggae\"\n\n[[3]]\n[1] \"pop\"\n\n[[4]]\n[1] \"hip hop\"\n\n[[5]]\n[1] \"R&B\"\n\n[[6]]\n[1] \"rock\"\n\n[[7]]\n[1] \"country\"\n\nNote that the numbers one through seven tell you the order of the objects stored in this list.\nTo give you a better idea of how lists in R work, I’ll give another example. In this example, I have some data gathered for the Grammys. I want to store this information in a list.\n\n\nmusic_event_title <-c(\"The 2020 Grammys\")\nmusic_event_description<-c(\"Music's biggest night!\")\nmusic_event_location<-c(\"Los Angeles\", \"Staples Center\")\nmusic_event_day<-c(\"Sunday\")\nmusic_event_time <-c(\"8:00 pm Eastern\", \"5:00 pm Pacific\")\nbig_categories<-c(\"Album of the Year\", \"Song of the Year\", \"Record of the Year\", \"Best New Artist\")\nwinners<-c(\"Billie Ellish\", \"Nipsey Hussle\", \"Lizzo\", \"Tyler the Creator\", \"Beyonce\", \"PJ Morton\")\nperformances<-c(\"Ariana Grande\", \"Demi Lovato\", \"Usher\",\"Nipsey Hussle Tribute\", \"Gary Clark Jr\", \"Nas\", \"Lil Nas X\" )\nmost_nominations<-c(12, 11, 10, 9)\n\nmusic_event_meeting <-rbind(music_event_day, music_event_time)\nmusic_event<-list(music_event_title, music_event_description, music_event_location, music_event_meeting, big_categories, winners, performances, most_nominations)\n\n\n\nI call this element music_event which will give me a list that looks like this.\n\n\nmusic_event\n\n\n[[1]]\n[1] \"The 2020 Grammys\"\n\n[[2]]\n[1] \"Music's biggest night!\"\n\n[[3]]\n[1] \"Los Angeles\"    \"Staples Center\"\n\n[[4]]\n                 [,1]              [,2]             \nmusic_event_day  \"Sunday\"          \"Sunday\"         \nmusic_event_time \"8:00 pm Eastern\" \"5:00 pm Pacific\"\n\n[[5]]\n[1] \"Album of the Year\"  \"Song of the Year\"   \"Record of the Year\"\n[4] \"Best New Artist\"   \n\n[[6]]\n[1] \"Billie Ellish\"     \"Nipsey Hussle\"     \"Lizzo\"            \n[4] \"Tyler the Creator\" \"Beyonce\"           \"PJ Morton\"        \n\n[[7]]\n[1] \"Ariana Grande\"         \"Demi Lovato\"          \n[3] \"Usher\"                 \"Nipsey Hussle Tribute\"\n[5] \"Gary Clark Jr\"         \"Nas\"                  \n[7] \"Lil Nas X\"            \n\n[[8]]\n[1] 12 11 10  9\n\nNaming Lists\nSimilar to naming elements in a vector, I can assign names to objects in a list using the names() function.\n\n\nmusic_event_names<-c(\"music_event_title\", \"music_event_description\", \"music_event_location\", \"music_event_meeting\", \"big_categories\", \"winners\", \"performances\", \"most_nominations\")\nnames(music_event)<-music_event_names\n\n\n\nOnce again, I’ll call music_event and my list’s elements will have names.\n\n\nmusic_event\n\n\n$music_event_title\n[1] \"The 2020 Grammys\"\n\n$music_event_description\n[1] \"Music's biggest night!\"\n\n$music_event_location\n[1] \"Los Angeles\"    \"Staples Center\"\n\n$music_event_meeting\n                 [,1]              [,2]             \nmusic_event_day  \"Sunday\"          \"Sunday\"         \nmusic_event_time \"8:00 pm Eastern\" \"5:00 pm Pacific\"\n\n$big_categories\n[1] \"Album of the Year\"  \"Song of the Year\"   \"Record of the Year\"\n[4] \"Best New Artist\"   \n\n$winners\n[1] \"Billie Ellish\"     \"Nipsey Hussle\"     \"Lizzo\"            \n[4] \"Tyler the Creator\" \"Beyonce\"           \"PJ Morton\"        \n\n$performances\n[1] \"Ariana Grande\"         \"Demi Lovato\"          \n[3] \"Usher\"                 \"Nipsey Hussle Tribute\"\n[5] \"Gary Clark Jr\"         \"Nas\"                  \n[7] \"Lil Nas X\"            \n\n$most_nominations\n[1] 12 11 10  9\n\nIf you call the names() function in a list without assigned names, the function will return NULL. This also applies to vectors.\nIndexing Lists\nJust as I did with vectors and matrices, I can also index lists. DataQuest tells me there are two different indexing operations used on lists:\nsingle brackets to return a list of selected elements []\ndouble brackets to return a single element [[]]\nFor example, I want to extract the third object in my list. I would type the following:\n\n\nmusic_event[3]\n\n\n$music_event_location\n[1] \"Los Angeles\"    \"Staples Center\"\n\n\n\ntypeof(music_event[3])\n\n\n[1] \"list\"\n\nNote that in this example, I use the typeof() function. This function allows me to check the data type of an object. When I checked the data type for this object, I see that it is a list.\nI could also use the following methods to return a list of selected items.\n\n\nmusic_event[\"music_event_location\"]\n\n\n$music_event_location\n[1] \"Los Angeles\"    \"Staples Center\"\n\n\n\nmusic_event[c(1,3)]\n\n\n$music_event_title\n[1] \"The 2020 Grammys\"\n\n$music_event_location\n[1] \"Los Angeles\"    \"Staples Center\"\n\nNow I’m going to use double brackets to return a single element. Again, I want extract the third object in my list. I’ll do the following:\n\n\nmusic_event[[3]]\n\n\n[1] \"Los Angeles\"    \"Staples Center\"\n\n\n\ntypeof(music_event[[3]])\n\n\n[1] \"character\"\n\nNote that when using the typeof() function to check the data type of this object, I see that it is a character data type.\nI could also use the following ways to return a single element.\n\n\nmusic_event[[\"music_event_location\"]]\n\n\n[1] \"Los Angeles\"    \"Staples Center\"\n\n\n\nmusic_event$\"music_event_location\"\n\n\n[1] \"Los Angeles\"    \"Staples Center\"\n\nTo return a value contained in a list element, I could do this:\n\n\nmusic_event[[c(3,2)]]\n\n\n[1] \"Staples Center\"\n\nManipulating Lists\nModifying List Elements\nI can index lists to change specific list elements. Recall the element in music_event_title:\n\n\n\nAs you can see the “The 2020 Grammys” is the element in music_event_title. I want to change this element to the official title of the Grammys ceremony. I would write it like this:\n\n\nmusic_event[[1]] <- \"The 62nd Annual Grammy Awards\"\nmusic_event\n\n\n$music_event_title\n[1] \"The 62nd Annual Grammy Awards\"\n\n$music_event_description\n[1] \"Music's biggest night!\"\n\n$music_event_location\n[1] \"Los Angeles\"    \"Staples Center\"\n\n$music_event_meeting\n                 [,1]              [,2]             \nmusic_event_day  \"Sunday\"          \"Sunday\"         \nmusic_event_time \"8:00 pm Eastern\" \"5:00 pm Pacific\"\n\n$big_categories\n[1] \"Album of the Year\"  \"Song of the Year\"   \"Record of the Year\"\n[4] \"Best New Artist\"   \n\n$winners\n[1] \"Billie Ellish\"     \"Nipsey Hussle\"     \"Lizzo\"            \n[4] \"Tyler the Creator\" \"Beyonce\"           \"PJ Morton\"        \n\n$performances\n[1] \"Ariana Grande\"         \"Demi Lovato\"          \n[3] \"Usher\"                 \"Nipsey Hussle Tribute\"\n[5] \"Gary Clark Jr\"         \"Nas\"                  \n[7] \"Lil Nas X\"            \n\n$most_nominations\n[1] 12 11 10  9\n\nI would first index the element I want to replace, then type its replacement. When I called the music_event list, you can see that the title has changed.\nLet’s do another example. Let’s look at the performances element.\n\n\n\nLet’s say I wanted to replace Demi Lovato with H.E.R. I would write the following:\n\n\nmusic_event[[c(7.2)]] <- \"H.E.R.\"\nmusic_event[7]\n\n\n$performances\n[1] \"H.E.R.\"\n\nAdding Elements to a List\nI could also add elements to a list. Let’s say I wanted to add an historic event that took place at last night’s Grammys. I can create an element called music_event_history add it to my list. When I call the music_event list, the new element is added.\n\n\nmusic_event_history <-c(\"Billie Ellish is the youngest person to take home awards in each of the four major categories.\")\nmusic_event[[9]] <- music_event_history\nmusic_event\n\n\n$music_event_title\n[1] \"The 62nd Annual Grammy Awards\"\n\n$music_event_description\n[1] \"Music's biggest night!\"\n\n$music_event_location\n[1] \"Los Angeles\"    \"Staples Center\"\n\n$music_event_meeting\n                 [,1]              [,2]             \nmusic_event_day  \"Sunday\"          \"Sunday\"         \nmusic_event_time \"8:00 pm Eastern\" \"5:00 pm Pacific\"\n\n$big_categories\n[1] \"Album of the Year\"  \"Song of the Year\"   \"Record of the Year\"\n[4] \"Best New Artist\"   \n\n$winners\n[1] \"Billie Ellish\"     \"Nipsey Hussle\"     \"Lizzo\"            \n[4] \"Tyler the Creator\" \"Beyonce\"           \"PJ Morton\"        \n\n$performances\n[1] \"H.E.R.\"\n\n$most_nominations\n[1] 12 11 10  9\n\n[[9]]\n[1] \"Billie Ellish is the youngest person to take home awards in each of the four major categories.\"\n\nI could also do it this way and get the same result.\n\n\nmusic_event[[\"music_event_history\"]] <-c(\"Billie Ellish is the youngest person to take home awards in each of the four major categories.\")\nmusic_event\n\n\n$music_event_title\n[1] \"The 62nd Annual Grammy Awards\"\n\n$music_event_description\n[1] \"Music's biggest night!\"\n\n$music_event_location\n[1] \"Los Angeles\"    \"Staples Center\"\n\n$music_event_meeting\n                 [,1]              [,2]             \nmusic_event_day  \"Sunday\"          \"Sunday\"         \nmusic_event_time \"8:00 pm Eastern\" \"5:00 pm Pacific\"\n\n$big_categories\n[1] \"Album of the Year\"  \"Song of the Year\"   \"Record of the Year\"\n[4] \"Best New Artist\"   \n\n$winners\n[1] \"Billie Ellish\"     \"Nipsey Hussle\"     \"Lizzo\"            \n[4] \"Tyler the Creator\" \"Beyonce\"           \"PJ Morton\"        \n\n$performances\n[1] \"H.E.R.\"\n\n$most_nominations\n[1] 12 11 10  9\n\n[[9]]\n[1] \"Billie Ellish is the youngest person to take home awards in each of the four major categories.\"\n\n$music_event_history\n[1] \"Billie Ellish is the youngest person to take home awards in each of the four major categories.\"\n\nCombining Lists\nI can combine lists too. Let’s recall the two lists I made earlier.\n\n\nmusic_genres <- list(\"jazz\", \"reggae\", \"pop\", \"hip hop\", \"R&B\", \"rock\", \"country\")\n\nmusic_event<-list(music_event_title, music_event_description, music_event_location, music_event_meeting, big_categories, winners, performances, most_nominations)\n\n\n\nWhen I combine the lists, I can see that the lists objects are combined into one list.\n\n\nmusic_night <-c(music_genres, music_event)\nmusic_night\n\n\n[[1]]\n[1] \"jazz\"\n\n[[2]]\n[1] \"reggae\"\n\n[[3]]\n[1] \"pop\"\n\n[[4]]\n[1] \"hip hop\"\n\n[[5]]\n[1] \"R&B\"\n\n[[6]]\n[1] \"rock\"\n\n[[7]]\n[1] \"country\"\n\n[[8]]\n[1] \"The 2020 Grammys\"\n\n[[9]]\n[1] \"Music's biggest night!\"\n\n[[10]]\n[1] \"Los Angeles\"    \"Staples Center\"\n\n[[11]]\n                 [,1]              [,2]             \nmusic_event_day  \"Sunday\"          \"Sunday\"         \nmusic_event_time \"8:00 pm Eastern\" \"5:00 pm Pacific\"\n\n[[12]]\n[1] \"Album of the Year\"  \"Song of the Year\"   \"Record of the Year\"\n[4] \"Best New Artist\"   \n\n[[13]]\n[1] \"Billie Ellish\"     \"Nipsey Hussle\"     \"Lizzo\"            \n[4] \"Tyler the Creator\" \"Beyonce\"           \"PJ Morton\"        \n\n[[14]]\n[1] \"Ariana Grande\"         \"Demi Lovato\"          \n[3] \"Usher\"                 \"Nipsey Hussle Tribute\"\n[5] \"Gary Clark Jr\"         \"Nas\"                  \n[7] \"Lil Nas X\"            \n\n[[15]]\n[1] 12 11 10  9\n\nNested Lists\nFinally for this post, I’ll cover nested lists. Nested Lists are lists inside of lists. Let’s take the previous example. What if instead of combining lists, I want to create a lists of lists. I would write:\n\n\ngrammy_night_list <- list(music_genres= music_genres, music_event = music_event)\ngrammy_night_list\n\n\n$music_genres\n$music_genres[[1]]\n[1] \"jazz\"\n\n$music_genres[[2]]\n[1] \"reggae\"\n\n$music_genres[[3]]\n[1] \"pop\"\n\n$music_genres[[4]]\n[1] \"hip hop\"\n\n$music_genres[[5]]\n[1] \"R&B\"\n\n$music_genres[[6]]\n[1] \"rock\"\n\n$music_genres[[7]]\n[1] \"country\"\n\n\n$music_event\n$music_event[[1]]\n[1] \"The 2020 Grammys\"\n\n$music_event[[2]]\n[1] \"Music's biggest night!\"\n\n$music_event[[3]]\n[1] \"Los Angeles\"    \"Staples Center\"\n\n$music_event[[4]]\n                 [,1]              [,2]             \nmusic_event_day  \"Sunday\"          \"Sunday\"         \nmusic_event_time \"8:00 pm Eastern\" \"5:00 pm Pacific\"\n\n$music_event[[5]]\n[1] \"Album of the Year\"  \"Song of the Year\"   \"Record of the Year\"\n[4] \"Best New Artist\"   \n\n$music_event[[6]]\n[1] \"Billie Ellish\"     \"Nipsey Hussle\"     \"Lizzo\"            \n[4] \"Tyler the Creator\" \"Beyonce\"           \"PJ Morton\"        \n\n$music_event[[7]]\n[1] \"Ariana Grande\"         \"Demi Lovato\"          \n[3] \"Usher\"                 \"Nipsey Hussle Tribute\"\n[5] \"Gary Clark Jr\"         \"Nas\"                  \n[7] \"Lil Nas X\"            \n\n$music_event[[8]]\n[1] 12 11 10  9\n\nThis resulting list contains my two lists, music_genres and music_events as objects.\nThis concludes my lesson in lists in R! I had a lot of fun using Grammy data for this post. Until next time..\n\n\n\n",
    "preview": "posts/working_with_lists 01-27-20/music_event_title.jpg",
    "last_modified": "2020-10-15T00:29:21-04:00",
    "input_file": {}
  },
  {
    "path": "posts/working_with_matrices 01-23-20/",
    "title": "Working With Matrices",
    "description": "Working with matrices in R.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-01-23",
    "categories": [
      "data science",
      "data types",
      "programming",
      "R",
      "matrices"
    ],
    "contents": "\n\n  \n  pre code {\n    white-space: pre-wrap;\n  }\nA matrix is a collection of elements of the same data type, with the data being arranged into rows and columns. Because it consists of both rows and columns, matrices are considered two-dimensional as opposed to vectors, which are considered one-dimensional.\nDataQuest analyzes university rankings for this lesson. However, for this post, I decided that I would analyze six of the highest-grossing films of all time. The data that I’ll be working with in this post comes from Box Office Mojo. Please note that for the last two columns, Budget in Millions and Domestic Opening in Millions, I rounded the numbers so the values in these columns are not exact.\n\n\n\nCombining Vectors into Matrices\nTo create a matrix using the data above, DataQuest taught me that I must first create vectors.\n\n\nendgame <-c(1, 2019, 181, 356, 357)\navatar <-c(2, 2009, 162, 237, 77)\ntitanic <-c(3, 1997, 194, 200, 28)\nstar_wars <-c(4, 2015, 138, 245, 248)\ninfinity_war <-c(5, 2018, 149, 316, 258)\njurassic_world <-c(6, 2015, 124, 150, 209)\n\n\n\nI can easily combine this vectors into a matrix using the function rbind(). The r in rbind() stands for row and this function allows us to combine multiple vectors and matrices by row.\n\n\nfilm_matrix <-rbind(endgame, avatar, titanic, star_wars, infinity_war, jurassic_world)\nfilm_matrix\n\n\n               [,1] [,2] [,3] [,4] [,5]\nendgame           1 2019  181  356  357\navatar            2 2009  162  237   77\ntitanic           3 1997  194  200   28\nstar_wars         4 2015  138  245  248\ninfinity_war      5 2018  149  316  258\njurassic_world    6 2015  124  150  209\n\nNaming Matrix Rows and Columns\nI then learned that I could name the rows and columns in a matrix. I could use the functions rownames() to name rows and colnames() to name columns. First, I stored the names of the columns into a vector called categories. I then used the function colnames() to assign those names to the columns in my matrix.\n\n\ncategories <- c(\"rank\", \"year\", \"runtime_minutes\", \"budget_millions\", \"domestic_opening_millions\")\ncolnames(film_matrix) <-categories\nfilm_matrix\n\n\n               rank year runtime_minutes budget_millions\nendgame           1 2019             181             356\navatar            2 2009             162             237\ntitanic           3 1997             194             200\nstar_wars         4 2015             138             245\ninfinity_war      5 2018             149             316\njurassic_world    6 2015             124             150\n               domestic_opening_millions\nendgame                              357\navatar                                77\ntitanic                               28\nstar_wars                            248\ninfinity_war                         258\njurassic_world                       209\n\nFinding Matrix Dimensions\nIf I wanted to identify the dimensions (the number of rows and columns) in a matrix, I would use the dim() function. The output of this function gives me two numbers. The first number is the number of rows; the second number is the number of columns.\n\n\ndim(film_matrix)\n\n\n[1] 6 5\n\nAdding Columns to Matrices\nEarlier in this post, I combined vectors into a matrix using rbind() and it allowed me to combine my vectors by row. The function, cbind() allows me to combine vectors and matrices by column.\nLet’s say I wanted to add the domestic gross of the films as a column to this matrix. First, I would get the domestic gross of the films. Next, I would use cbind() to add the domestic_gross_millions column to the existing matrix.\n\n\ndomestic_gross_millions<-c(858, 761, 659, 937, 679, 652)\ncbind(film_matrix, domestic_gross_millions)\n\n\n               rank year runtime_minutes budget_millions\nendgame           1 2019             181             356\navatar            2 2009             162             237\ntitanic           3 1997             194             200\nstar_wars         4 2015             138             245\ninfinity_war      5 2018             149             316\njurassic_world    6 2015             124             150\n               domestic_opening_millions domestic_gross_millions\nendgame                              357                     858\navatar                                77                     761\ntitanic                               28                     659\nstar_wars                            248                     937\ninfinity_war                         258                     679\njurassic_world                       209                     652\n\nI then stored the result in a new matrix called entire_matrix.\n\n\nentire_matrix <- cbind(film_matrix, domestic_gross_millions)\nentire_matrix\n\n\n               rank year runtime_minutes budget_millions\nendgame           1 2019             181             356\navatar            2 2009             162             237\ntitanic           3 1997             194             200\nstar_wars         4 2015             138             245\ninfinity_war      5 2018             149             316\njurassic_world    6 2015             124             150\n               domestic_opening_millions domestic_gross_millions\nendgame                              357                     858\navatar                                77                     761\ntitanic                               28                     659\nstar_wars                            248                     937\ninfinity_war                         258                     679\njurassic_world                       209                     652\n\nWhen adding a vector to a matrix, it’s important to make sure that the new vector is the same length as the number of rows and columns in the matrix.\nIndexing Matrices\nJust as I indexed vectors, I learned that I could also index matrices. Since matrices are two-dimensional, they can be indexed in the following ways:\nindex to select specific values\nindex to select specific rows and columns\nIndexing By Element\nLet’s say I wanted to extract the year that Avengers: Infinity War was released. I have to specify the location of this element by row and and column. In the screenshot below, you can see that Infinity War is in row 5 and the year is in column 2.\n\n\n\n\n\nentire_matrix[5,2]\n\n\n[1] 2018\n\nI can also index matrices by row and column names instead of position:\n\n\nentire_matrix[\"infinity_war\", \"year\"]\n\n\n[1] 2018\n\nI can specify the range of columns since the budget_in_millions and domestic_gross_millions columns are next to each other.\n\n\nentire_matrix[5, 4:5]\n\n\n          budget_millions domestic_opening_millions \n                      316                       258 \n\nI can also index columns are not next to each other. Let’s say I wanted index elements from the columns rank and runtime_minutes. Here I index these columns in two ways. The first example is by position, the second example is by name.\n\n\nentire_matrix[c(3,5), c(1,3)]\n\n\n             rank runtime_minutes\ntitanic         3             194\ninfinity_war    5             149\n\n\n\nentire_matrix[c(\"titanic\", \"infinity_war\"), c(\"rank\", \"runtime_minutes\")]\n\n\n             rank runtime_minutes\ntitanic         3             194\ninfinity_war    5             149\n\nIndex By Row and Column\nAs mentioned, I can index to select a specific row or column. Let’s say I want to extract all the rankings for Avatar. All the rankings for Avatar are in row 2 of my matrix. I would indicate that I want to index all the elements of row 2 and leave the column position blank.\n\n\nentire_matrix[\"avatar\", ]\n\n\n                     rank                      year \n                        2                      2009 \n          runtime_minutes           budget_millions \n                      162                       237 \ndomestic_opening_millions   domestic_gross_millions \n                       77                       761 \n\nWhen I write an expression to index an entire row or column, I only need to specify the name of that row or column. The other position is left blank. In this next example, I index an entire column. Since row comes before column, I leave the row blank.\n\n\nentire_matrix[ , \"budget_millions\"]\n\n\n       endgame         avatar        titanic      star_wars \n           356            237            200            245 \n  infinity_war jurassic_world \n           316            150 \n\nI could also index to select multiple rows and columns. If I want to extract the year, runtime_minutes and budget_millions columns, I would write:\n\n\nentire_matrix[,c(\"year\", \"runtime_minutes\", \"budget_millions\")]\n\n\n               year runtime_minutes budget_millions\nendgame        2019             181             356\navatar         2009             162             237\ntitanic        1997             194             200\nstar_wars      2015             138             245\ninfinity_war   2018             149             316\njurassic_world 2015             124             150\n\n\n\nentire_matrix[,c(2,3,4)]\n\n\n               year runtime_minutes budget_millions\nendgame        2019             181             356\navatar         2009             162             237\ntitanic        1997             194             200\nstar_wars      2015             138             245\ninfinity_war   2018             149             316\njurassic_world 2015             124             150\n\nIf I want to extract the star_wars, infinity_war and jurassic_world rows, I would write:\n\n\nentire_matrix[c(\"star_wars\",\"infinity_war\",\"jurassic_world\"), ]\n\n\n               rank year runtime_minutes budget_millions\nstar_wars         4 2015             138             245\ninfinity_war      5 2018             149             316\njurassic_world    6 2015             124             150\n               domestic_opening_millions domestic_gross_millions\nstar_wars                            248                     937\ninfinity_war                         258                     679\njurassic_world                       209                     652\n\n\n\nentire_matrix[c(4,5,6), ]\n\n\n               rank year runtime_minutes budget_millions\nstar_wars         4 2015             138             245\ninfinity_war      5 2018             149             316\njurassic_world    6 2015             124             150\n               domestic_opening_millions domestic_gross_millions\nstar_wars                            248                     937\ninfinity_war                         258                     679\njurassic_world                       209                     652\n\nRanking Films\nI can use the rank() function to specify the categories I want to rank the films by. This function returns a vector of numeric values.\n\n\nrank(entire_matrix[,\"domestic_opening_millions\"])\n\n\n       endgame         avatar        titanic      star_wars \n             6              2              1              4 \n  infinity_war jurassic_world \n             5              3 \n\nCalculating the Sum Of Values in A Vector and Matrix\nThis last section of this post is going to cover calculating the sum of values in a vector and a matrix.\nI can calculate the sum of the values in a vector or matrix using the sum() function.\nLet’s recall the original vector I created called titanic.\n\n\ntitanic <-c(3, 1997, 194, 200, 28)\n\n\n\nI want to add these values in the vector. To do that, I would write this:\n\n\nsum(titanic)\n\n\n[1] 2422\n\nAs you can see the sum of this vector is 2422. What if I wanted to calculate all the values of the titanic row of my matrix?\n\n\nsum(entire_matrix[\"titanic\", ])\n\n\n[1] 3081\n\nHere the sum of value in my titanic row is 3081. Why are the two sums different? Remember that I added the domestic_gross_millions column to my matrix after the matrix was created. The original vector does not include the value for domestic_gross_millions.\nJust as I did the sum of the values in a row, I can do the same for a column. If I want to add up all the values in domestic_opening_millions column, I would type the following:\n\n\nsum(entire_matrix[, \"domestic_opening_millions\"])\n\n\n[1] 1177\n\nSo the sum of all the values in the domestic_opening_millions column is 1177. This means that combined opening weekend total for all the films is about $1,117,000,000!\nThis just about does it for matrices in R! For the next post, I’ll get into lists in R.\n\n\n\n",
    "preview": "posts/working_with_matrices 01-23-20/highest_grossing_films-table.jpg",
    "last_modified": "2020-10-15T00:21:11-04:00",
    "input_file": {}
  },
  {
    "path": "posts/working_with_vectors_two 01-16-20/",
    "title": "Working With Vectors(Part 2)",
    "description": "Part two of working with vectors in R.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-01-16",
    "categories": [
      "data science",
      "data types",
      "programming",
      "R",
      "vectors"
    ],
    "contents": "\nThis post is a continuation of what I learned in the DataQuest lesson, Working with Vectors. If you want to read part one, click here.\nLogical Operators\nLike many other programming languages, R uses comparison operators, also known as logical operators to compare values. When comparing two values, both values must satisfy the condition for the R interpreter to return TRUE. If the values do not satisfy the condition, the R interpreter will return FALSE.\nThe logical operators are:\nGreater than: >\nLess than: <\nGreater than or equal to: =>\nLess than or equal to: <=\nEqual to: ==\nNot equal to: !=\nThe TRUE and FALSE values are another data type in R called logical. The logical data type only consists of values TRUE and FALSE.\nFor an example, let’s continue with the tea example from the last post and introduce a new vector, the smoothie_prices vector. If I take the average value of tea_prices and compare it to the average value of smoothie_prices, I’ll get the following below:\n\n\ntea_flavors <- c(\"chai\", \"matcha\", \"black\", \"green\", \"white\")\ntea_prices <- c(5, 4, 2, 2, 3)\nnames(tea_prices) <- tea_flavors\nsmoothie_prices <-c(5, 5.5, 4, 4.5, 6)\nmean(tea_prices) < mean(smoothie_prices)\n\n\n[1] TRUE\n\nComparing Single Values Against Vectors\nI’ll use an example from my previous post. These are the tea flavors and their prices below.\n\n\ntea_prices\n\n\n  chai matcha  black  green  white \n     5      4      2      2      3 \n\nIf I want to compare the price of white tea to the prices of the other teas, the syntax would look like this:\ntea_prices[“white”] > tea_prices\nLet’s see what happens when I type the above expression in the R interpreter.\n\n\ntea_prices[\"white\"] > tea_prices\n\n\n  chai matcha  black  green  white \n FALSE  FALSE   TRUE   TRUE  FALSE \n\nAn important concept in R is understanding how R works with vectors of different lengths. When comparing a vector that contains a single value to a vector that contains multiple values, R replicates the shorter vector until it is the same length as the longer vector. In DataQuest, they break down their example into a table so that it is easier for students to understand. I’ll do the same here because this is what made me better understand what happened in the interpreter.\nHow R works with vectors of different lengthsWhen I compare the price of white tea(a vector containing a single value) to the vector containing the all the tea prices, R replicated the price of the white tea until it became the same length as the tea_prices vector. We will revisit this concept later on.\nLogical data can also be stored in vectors. Let’s say I wanted to store the results of comparing the price of white tea to the other teas, I can write the following:\n\n\ncompare_teas <- tea_prices[\"white\"] > tea_prices\n\n\n\nIf I use the typeof() function to check the data type of the compare_teas vector, I get:\n\n\ntypeof(compare_teas)\n\n\n[1] \"logical\"\n\nLogical Indexing\nNow that I’ve learned how to index by position and name, I was introduced to a new type of indexing called logical_indexing. DataQuest gives a great explanation of logical indexing:\n\n\"Logical indexing will compare each value in a target vector against the\ncorresponding value in a logical vector. If the corresponding value is TRUE, the\nresulting vector will contain that value. If the corresponding value is FALSE, the\nresulting vector will not contain that value.”\n\nFor example, if I wanted to create a new vector containing only the teas whose prices are greater than price of the white tea, I would write:\n\n\nabove_tea_prices <- tea_prices > tea_prices[\"white\"]\ntea_prices[above_tea_prices]\n\n\n  chai matcha \n     5      4 \n\nPerforming Arithmetic On Vectors\nI learned that I could add, multiply or divide vectors. Let’s look at the example below:\n\n\ntea_prices <- c(5, 4, 2, 2, 3)\nsmoothie_prices <- c(5, 5.5, 4, 4.5, 6)\nlatte_prices <- c(3.5, 3, 4.5, 4, 5)\ndrinks <- (tea_prices + smoothie_prices + latte_prices)\ndrinks\n\n\n[1] 13.5 12.5 10.5 10.5 14.0\n\n\n\ndrinks <- (tea_prices + smoothie_prices + latte_prices)/3\nmean(drinks)\n\n\n[1] 4.066667\n\nNotice that when I added the prices of the teas, smoothies and lattes in a vector called drinks, I got a vector containing five values. According to DataQuest, this is what is known as vector arithmetic. When performing arithmetic on vectors, operations are performed between values in order of position. When I added all the drink prices together, this is how the operation was performed:\nAdding drink pricesThe ability to perform arithmetic operations on every element of multiple vectors at once is a very powerful feature of R.\nVector Recycling\nI talked a bit earlier about vector recycling. To recap when there’s a mismatch in the length of the two vectors being compared, R repeats or recycles the shorter vector until it matches the length of the longer vector. For this next example, I shortened the length of the smoothie_prices vector. However, when I did the addition, I got this warning message.\n\n\ntea_prices <- c(5, 4, 2, 2, 3)\nsmoothie_prices <- c(4.5, 6)\nlatte_prices <- c(3.5, 3, 4.5, 4, 5)\ndrinks <- (tea_prices + smoothie_prices + latte_prices)\n\n\n\nThis message alerts me of the possibility that the different vector lengths were not intended. When I call the drinks vector, the operation is still performed. I also took the average of the prices in the drinks vector.\n\n\ndrinks\n\n\n[1] 13.0 13.0 11.0 12.0 12.5\n\n\n\nmean(drinks)\n\n\n[1] 12.3\n\nAdding drink pricesThe values highlighted in red represent the recycled values of the smoothie_prices vector. The problem with vector recycling is that although R recycled the incomplete smoothie_prices vector and calculated the average price of a drink, the average is not accurate. The average is not accurate because some of the elements of the smoothie_prices vector are missing. This brings me to the last topic for this post.\nAppending Elements To A Vector\nLet’s say I wanted to add the other prices to the smoothie_prices vector. I could add or append values to the smoothie_prices vector. Let’s look at this example:\n\n\nsmoothie_prices <- c(4.5, 6)\nsmoothie_prices <- c(smoothie_prices, 4, 5, 5.5)\nsmoothie_prices\n\n\n[1] 4.5 6.0 4.0 5.0 5.5\n\nI used the c() function to create a new vector consisting of the existing vector plus the new elements I want to add. I don’t know about you, but this is much better than retyping the smoothie_prices vector.\nAnd on that note, this wraps up part two of what I learned about vectors in R! My next post will introduce a brand new topic!\n\n\n\n",
    "preview": {},
    "last_modified": "2020-10-13T20:09:34-04:00",
    "input_file": {}
  },
  {
    "path": "posts/working_with_vectors_one 01-13-20/",
    "title": "Working With Vectors(Part 1)",
    "description": "Part one of working with vectors in R.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-01-13",
    "categories": [
      "data science",
      "data types",
      "programming",
      "R",
      "vectors"
    ],
    "contents": "\nFor this post, I’ll discuss the working with vectors lesson on DataQuest’s Data Analyst in R track. I’m going to dive deeper into vectors, talking about indexing in R and R’s different data types. There was so much that I learned in this lesson that I decided to break this topic up into two posts. So let’s jump right in!\nAs mentioned in my last post, vectors are storage objects that stores a sequence of values. Vectors can be indexed to select the subset of elements they contain. Each element of a vector is assigned a position. This reminds me of lists in Python with one key difference. R is an 1-indexed programming language so the first element in a vector is assigned the position of one. This is very different from what I learned in Python or JavaScript where indexing starts at zero. I think it’s a bit easier though because when we count we usually start from one.\nIndexing By Position\nYou can index vectors by position using a single element, a range of elements or multiple elements. Let’s take the example vector from my previous Intro To R Programming post.\n\n\n\nIndex Using a Single Element:\n\n\ntea_price[2]\n\n\n[1] 4\n\nIndex by Range of Elements:\n\n\ntea_price[2:4]\n\n\n[1] 4 2 2\n\nIndex Using Multiple Elements:\n\n\ntea_price[c(1, 3, 5)]\n\n\n[1] 5 2 3\n\nR’s Data Types\nLike other programming languages, R also has data types. In this lesson, DataQuest presents three basic data types:\nNumeric(Double)– consists of numbers( 4, 32.6, 32.67521, -2 , -7.9)\nCharacter– consists of letters, numbers and special characters. Character data is surrounded by quotation marks (“snake”, “&”, “%” , “special0964”, “cool + beans”)\nLogical-stores boolean values TRUE and FALSE\nTo find out the type of data type I’m working with, I learned to use typeof() function.\nThis is where things got a bit confusing for me. I decided to try this for myself in both R Studio and the R console that comes with R. I ended up with the following:\n\n\ntypeof(88)\n\n\n[1] \"double\"\n\ntypeof(6.7)\n\n\n[1] \"double\"\n\ntypeof(-0.75)\n\n\n[1] \"double\"\n\ntypeof(-4.93)\n\n\n[1] \"double\"\n\ntypeof(47)\n\n\n[1] \"double\"\n\ntypeof(392)\n\n\n[1] \"double\"\n\ntypeof(9.6666667)\n\n\n[1] \"double\"\n\nAs you can see when I use the typeof() function on both whole numbers and decimals, it doesn’t come back as numeric, it comes back as double. From the lesson, I understood double to mean just decimal numbers.\nI decided to consult the #rstats community on Twitter.\nPosing a question to #rstats twitterA few members of the #rstats community, Maarten Demeyer, Tyson Barrett, and Colin Fay came through with helpful responses that helped clarify the confusion I had. A special thank you to them! Check out their responses here.\nWhat I gathered from these responses and further research is that numeric is a class and the double data type fall into that class. There are also more data types in R but I won’t get into those right now.\nNames() Function\nI also learned that in R you can assign names to vector elements. To do this, we use the names() function. Again, taking the example from my Intro to R Programming post, if I wanted to assign the values contained in tea_flavors to the values stored in tea_prices, it would look like this:\n\n\ntea_flavors <- c(\"chai\", \"matcha\", \"black\", \"green\", \"white\")\ntea_prices <- c(5, 4, 2, 2, 3)\nnames(tea_prices) <- tea_flavors\ntea_prices\n\n\n  chai matcha  black  green  white \n     5      4      2      2      3 \n\nI could also use the names() function to return the names of the elements in a vector like this:\n\n[1] \"chai\"   \"matcha\" \"black\"  \"green\"  \"white\" \n\nIndexing By Name\nLastly for part one, I’ll talk about indexing by name. In R, you can index vectors by name. Note that I get the same result when I index by name and position.\n\n\ntea_prices[\"matcha\"]\n\n\nmatcha \n     4 \n\ntea_prices[2]\n\n\nmatcha \n     4 \n\nEarlier in this post you saw how I indexed by position using multiple elements. You can do the same when indexing by name.\n\n\ntea_prices[c(\"black\", \"white\")]\n\n\nblack white \n    2     3 \n\nWhew, that was a lot to cover! That’s it for Part One working with vectors. Part Two is coming soon!\n\n\n\n",
    "preview": {},
    "last_modified": "2020-10-13T20:08:23-04:00",
    "input_file": {}
  },
  {
    "path": "posts/intro_to_R 01-08-20/",
    "title": "Intro to R Programming",
    "description": "My first introduction to the R programming language.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-01-09",
    "categories": [
      "data science",
      "programming",
      "R",
      "vectors"
    ],
    "contents": "\nR is a language I’ve been curious about for some time. I started learning a bit about Python when I kept reading and hearing about R. Python and R are the two programming languages most commonly used in data science. Out of curiosity and a bit of boredom, I decided to learn a bit of R syntax. After that experience, I decided to continue learning R. I decided that I would learn more R using DataQuest’s Data Analyst in R track.\nThis is the first of a series of posts documenting what I’m learning in the Data Analyst in R track. In this post, I’ll discuss the first lesson of the track, Introduction to Programming in R.\nIntroduction to Programming in R\nMuch like the JavaScript and Python lessons I’ve had prior, this lesson started off with basic math and order of operations. Like those languages, R uses the order of operations when evaluating expressions.\n217 – 9\n415 + 156\n7 * 18\n144/4\n(45 – 3)/6\n(17 * 8) – 4\nAfter calculations like this, I moved on to variables. This is where things got interesting. Although the creation of variables in R is similar to that of JavaScript and Python, one key difference is the assignment operator. Where other programming languages use the equal sign(=), R uses an arrow (<-) to assign values. Let’s say I wanted to create some variables using the names of teas. It would look like this :\nPython/JavaScript:\nchai = 5\nmatcha = 4\nblack = 2\ngreen = 2\nwhite = 3\nR:\nchai <- 5\nmatcha <- 4\nblack <- 2\ngreen <- 2\nwhite <- 3\nAs with other languages, when naming variables in R, there are rules to follow. Variables can contain numbers, letters and underscores, special characters are not allowed and variable names cannot begin with a number.\nWhat was new to me, however, is that in R a dot can be used in a variable name. I believe this is the first time I’ve come across this rule in programming. Variable names can begin with a dot but the dot cannot be followed by a number.\nDataQuest provides a takeaway(I’ll discuss what this is in a bit) that gives us a link to this awesome resource from R-bloggers about variable naming conventions.\nNext, I moved on to vectors. Vectors are storage objects that store a sequence of values. These values are assigned to a single variable. To create a vector you would write:\n\n\ntea_prices <- c(5, 4, 2, 2, 3)\ntea_flavors <- c(\"chai\", \"matcha\", \"black\", \"green\", \"white\")\n\n\n\nThe c() is a function that stands for concatenate. It takes multiple values as input and stores these values as one variable to create the vector. You can also use variable names to create a vector as I did with the tea_flavors vector.\nR has built-in functions. Some of them include:\nmean() – average of values in vector\nsum()– sum of values in vector\nlength()-total number of elements in vector\nmin()-smallest value in vector\nmax()-largest value in vector\nThese functions allow to quickly operate across all the values in the vector. For example, if I wanted to know the average of tea_prices, I would use the mean() function the average price of teas and store that value in a vector like so:\n\n\ntea_prices <- c(5, 4, 2, 2, 3)\ntea_price_avg <- mean(tea_prices)\ntea_price_avg\n\n\n[1] 3.2\n\nIf I wanted to know how many elements were in tea_flavors, I would write:\n\n\ntea_flavors <- c(\"chai\", \"matcha\", \"black\", \"green\", \"white\")\nlength(tea_flavors)\n\n\n[1] 5\n\nI mentioned a bit earlier in the post about a takeaway. At the end of each lesson, DataQuest gives you a takeaway, a summary of what you learned in the lesson. This can be downloaded as a PDF and it’s great for reviewing concepts and syntax. It also gives you links to learn more about topics in the lesson. I can access my takeaways on my computer or my phone and I read them frequently. They have been really helpful for me as I forget the syntax rules.\nAnd with that said, this wraps up intro to programming in R! I’ll get more into vectors in my next post.\n\n\n\n",
    "preview": {},
    "last_modified": "2020-10-13T20:05:36-04:00",
    "input_file": {}
  },
  {
    "path": "posts/first post 01-08-20/",
    "title": "Why Data Science?",
    "description": "My decision to pursue data science.",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-01-08",
    "categories": [
      "data science",
      "programming",
      "R",
      "Python",
      "books"
    ],
    "contents": "\nFor the past several years, I’ve explored different career paths in tech. I’ve played around with web development but found that was not a good fit for me. For a long time, I wanted to be a UX designer which later turned into UX writing. I spoke with people who worked in UX, attended meetups and different events that were UX focused. Many of the classes I took as part of my graduate program were design-focused.\nAlthough I enjoyed learning UX, as I completed my final projects for these classes, I came to the realization that this was not what I wanted to do as a career. This became even more clear after I failed to land a huge job opportunity. After my failed job interview, I began reevaluating my career interests and goals. Why was I interested in UX in the first place? Was it genuine interest or was I pursuing it because it looked cool? Why did I want to be in tech in the first place? After taking some time to explore the answers to these questions and more, it brought me back to data, a huge topic that has been of interest to me for many years.\nMy interest in data really started with data journalism. I didn’t want to be a data journalist, but I did and still do enjoy the work of people like Mona Chalabi and I follow publications like The Guardian, Five Thirty-Eight and The New York Times. Last year I took a course in my program called Big Data and Media. It was in this class that I learned about the potential of data and analytics. The class was given the assignment to choose from a list of links to articles or interviews about data and summarize it. I chose an NPR interview with Cathy O’Neil, author of Weapons of Math Destruction. In the interview, she talked about the dangers of relying on big data analytics to solve problems, using public education and recidivism as examples of areas where using big data analytics to solve problems has caused huge issues. After listening to the interview and watching her TED talk, I became really interested in learning more.\n\n\n\nThis summer, I took a Python for Data Science course and I purchased Cathy O’Neil’s book (both Kindle and Audible) which I’m currently reading. In December, I completed my final class for my grad program, Market Research for Media Managers which really helped cement my interest in data, particularly data in the media and entertainment industry. Through this course, I’ve learned about programmatic buying and addressability, projectability (who do the results represents and with what reliability), and much more.\nI am participating in the Data Executives Program where I am learning about different tools and exploring what interests me. In addition to Python, I’ve looked into learning R, Excel, SQL, and Tableau. I have since decided to learn R and SQL for now. I plan on attending meetups and different data-science focused events. I also plan to do more reading on data science-related topics. I recently purchased Charles Wheelan’s Naked Statistics and Data Science for the Layman by Annalyn Ng and Kenneth Soo. I am especially excited to dive into more books like Weapons of Math Destruction that address how negative bias has become embedded in our data. Algorithms of Oppression by Dr. Safiya Umoja Noble and Invisible Women by Caroline Criado Perez, to name a few, are books that are at the top of my list. In all, I am excited to learn more about data science and I look forward to where my interests will take me.\n\n\n\n",
    "preview": "posts/first post 01-08-20/weaponsofmathdestruction.jpg",
    "last_modified": "2020-10-15T00:21:35-04:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to Data Sci Dani",
    "description": "\"One of the greatest discoveries a man makes, one of his great surprises, is to find he can do what he was afraid he couldn’t do.\"— Henry Ford",
    "author": [
      {
        "name": "Danielle Brantley",
        "url": "https://gist.github.com/danielle-b"
      }
    ],
    "date": "2020-01-07",
    "categories": [
      "data science",
      "programming",
      "learning",
      "statistics"
    ],
    "contents": "\nI’ve decided to face my fear and enter the world of data science. I’ve always admired data visualizations and have long been interested in how data is used to make business decisions. However, the idea of programming combined with statistics has always intimidated me a bit. My goal is to become a data analyst (and eventually a data scientist) by strengthening my programming and statistical skills. I’ll share what I’m learning; I’ll discuss projects, books/articles I’ve read and really any thoughts I have pertaining to data science.\n\n\n\n",
    "preview": {},
    "last_modified": "2020-10-13T20:04:12-04:00",
    "input_file": {}
  }
]
